{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# from models.load import TrainedModels\n",
    "\n",
    "from utils.eval import save_iou_results\n",
    "from utils.engine import get_iou_types, evaluate\n",
    "from models.load import get_trained_model\n",
    "from utils.eval import get_ap_ar, get_num_fps, get_num_fns, get_num_tps\n",
    "from utils.print import print_title\n",
    "from utils.init import reproducibility, clean_memory_get_device\n",
    "from data.load import get_datasets, get_dataloaders\n",
    "from data.paths import MIMIC_EYE_PATH\n",
    "from tqdm import tqdm\n",
    "from utils.train import  get_coco_eval_params\n",
    "from utils.coco_eval import get_eval_params_dict\n",
    "\n",
    "## Suppress the assignement warning from pandas.\n",
    "pd.options.mode.chained_assignment = None  # default='warn\n",
    "\n",
    "## Supress user warning\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "\n",
    "class Test(Enum):\n",
    "    A = \"a\"\n",
    "    B = \"b\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "\n",
    "class TrainedModels(Enum):\n",
    "    mobilenet_baseline = \"val_lesion-detection_ap_0_1655_test_lesion-detection_ap_0_1648_epoch50_03-15-2023 16-43-54_lesion_dsetection_baseline_mobilenet\"  # mobilenet baseline\n",
    "    mobilenet_with_fix = \"val_lesion-detection_ap_0_1918_test_lesion-detection_ap_0_1903_epoch16_03-16-2023 11-34-10_lesion_dsetection_with_fixation_mobilenet\"\n",
    "    resnet18_baseline = \"val_lesion-detection_ap_0_1973_test_lesion-detection_ap_0_2010_epoch22_03-16-2023 19-44-55_lesion_dsetection_baseline_resnet\"\n",
    "    resnet18_with_fix = \"val_lesion-detection_ap_0_1951_test_lesion-detection_ap_0_2195_epoch12_03-17-2023 00-31-54_lesion_dsetection_with_fixation_resnet\"\n",
    "    densenet161_baseline = \"val_lesion-detection_ap_0_1990_test_lesion-detection_ap_0_2085_epoch5_03-17-2023 08-53-33_lesion_dsetection_baseline_densenet161\"\n",
    "    densenet161_with_fix = \"val_lesion-detection_ap_0_2120_test_lesion-detection_ap_0_2104_epoch12_03-17-2023 18-36-01_lesion_dsetection_with_fixation_densenet161\"\n",
    "    efficientnet_b5_baseline = \"val_lesion-detection_ap_0_1898_test_lesion-detection_ap_0_2055_epoch5_03-17-2023 23-30-57_lesion_dsetection_baseline_efficientnet_b5\"\n",
    "    efficientnet_b5_with_fix = \"val_lesion-detection_ap_0_2117_test_lesion-detection_ap_0_2190_epoch8_03-18-2023 12-29-20_lesion_dsetection_with_fixation_efficientnet_b5\"\n",
    "    efficientnet_b0_baseline = \"val_lesion-detection_ap_0_1934_test_lesion-detection_ap_0_1858_epoch10_03-18-2023 23-50-47_lesion_dsetection_baseline_efficientnet_b0\"\n",
    "    efficientnet_b0_with_fix = \"val_lesion-detection_ap_0_2191_test_lesion-detection_ap_0_2162_epoch10_03-18-2023 19-38-11_lesion_dsetection_with_fixation_efficientnet_b0\"\n",
    "    convnext_base_with_fix = \"val_lesion-detection_ap_0_2610_test_lesion-detection_ap_0_2548_epoch22_03-22-2023 02-55-37_lesion_dsetection_with_fixation_convnext_base\"\n",
    "    convnext_base_baseline = \"val_lesion-detection_ap_0_2426_test_lesion-detection_ap_0_2325_epoch20_03-22-2023 11-53-53_lesion_dsetection_baseline_convnext_base\"\n",
    "    vgg16_with_fix = \"val_lesion-detection_ap_0_2301_test_lesion-detection_ap_0_2186_epoch22_03-20-2023 19-26-02_lesion_dsetection_with_fixation_vgg16\"\n",
    "    vgg16_baseline = \"val_lesion-detection_ap_0_2113_test_lesion-detection_ap_0_2068_epoch12_03-21-2023 00-45-24_lesion_dsetection_baseline_vgg16\"\n",
    "    regnet_y_8gf_with_fix = \"val_lesion-detection_ap_0_2267_test_lesion-detection_ap_0_2029_epoch12_03-21-2023 11-28-48_lesion_dsetection_with_fixation_regnet_y_8gf\"\n",
    "    regnet_y_8gf_baseline = \"val_lesion-detection_ap_0_1883_test_lesion-detection_ap_0_1658_epoch13_03-21-2023 15-22-32_lesion_dsetection_baseline_regnet_y_8gf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(Test)[0] == Test.A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_iou_thrs = np.array([0.5, 0.55, 0.6, 0.65, 0.7, 0.75, 0.8, 0.85, 0.9, 0.95])\n",
    "score_thresholds = [0.05]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/16 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This notebook will running on device: [CUDA]\n",
      "Using pretrained backbone. mobilenet_v3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/16 [00:01<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using SGD as optimizer with lr=0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "__init__() got an unexpected keyword argument 'fiaxtions_mode_input'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 41\u001b[0m\n\u001b[0;32m     20\u001b[0m iou_types \u001b[39m=\u001b[39m get_iou_types(model, setup)\n\u001b[0;32m     22\u001b[0m dataset_params_dict \u001b[39m=\u001b[39m {\n\u001b[0;32m     23\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mMIMIC_EYE_PATH\u001b[39m\u001b[39m\"\u001b[39m: MIMIC_EYE_PATH,\n\u001b[0;32m     24\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mlabels_cols\u001b[39m\u001b[39m\"\u001b[39m: setup\u001b[39m.\u001b[39mlesion_label_cols,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     38\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mimage_std\u001b[39m\u001b[39m\"\u001b[39m: setup\u001b[39m.\u001b[39mimage_std,\n\u001b[0;32m     39\u001b[0m }\n\u001b[1;32m---> 41\u001b[0m detect_eval_dataset, train_dataset, val_dataset, test_dataset \u001b[39m=\u001b[39m get_datasets(\n\u001b[0;32m     42\u001b[0m     dataset_params_dict\u001b[39m=\u001b[39;49mdataset_params_dict,\n\u001b[0;32m     43\u001b[0m )\n\u001b[0;32m     45\u001b[0m train_dataloader, val_dataloader, test_dataloader \u001b[39m=\u001b[39m get_dataloaders(\n\u001b[0;32m     46\u001b[0m     train_dataset,\n\u001b[0;32m     47\u001b[0m     val_dataset,\n\u001b[0;32m     48\u001b[0m     test_dataset,\n\u001b[0;32m     49\u001b[0m     batch_size\u001b[39m=\u001b[39msetup\u001b[39m.\u001b[39mbatch_size,\n\u001b[0;32m     50\u001b[0m )\n\u001b[0;32m     52\u001b[0m train_coco \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\mike8\\OneDrive\\文件\\GitHub\\MIMIC-Eye-applications\\data\\load.py:48\u001b[0m, in \u001b[0;36mget_datasets\u001b[1;34m(dataset_params_dict)\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_datasets\u001b[39m(\n\u001b[0;32m     45\u001b[0m     dataset_params_dict: Dict,\n\u001b[0;32m     46\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[ReflacxDataset, ReflacxDataset, ReflacxDataset, ReflacxDataset]:\n\u001b[1;32m---> 48\u001b[0m     detect_eval_dataset \u001b[39m=\u001b[39m ReflacxDataset(\n\u001b[0;32m     49\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m{\n\u001b[0;32m     50\u001b[0m             \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mdataset_params_dict,\n\u001b[0;32m     51\u001b[0m         },\n\u001b[0;32m     52\u001b[0m     )\n\u001b[0;32m     54\u001b[0m     train_dataset \u001b[39m=\u001b[39m ReflacxDataset(\n\u001b[0;32m     55\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mdataset_params_dict,\n\u001b[0;32m     56\u001b[0m         split_str\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m     57\u001b[0m         random_flip\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[0;32m     58\u001b[0m     )\n\u001b[0;32m     60\u001b[0m     val_dataset \u001b[39m=\u001b[39m ReflacxDataset(\n\u001b[0;32m     61\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mdataset_params_dict,\n\u001b[0;32m     62\u001b[0m         split_str\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mval\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m     63\u001b[0m         random_flip\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m     64\u001b[0m     )\n",
      "\u001b[1;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'fiaxtions_mode_input'"
     ]
    }
   ],
   "source": [
    "from data.strs import SourceStrs, TaskStrs\n",
    "\n",
    "# just generate for the test set.\n",
    "\n",
    "for select_model in tqdm(list(TrainedModels)):\n",
    "\n",
    "    for score_thrs in score_thresholds:\n",
    "\n",
    "        device = clean_memory_get_device()\n",
    "        reproducibility()\n",
    "\n",
    "        model, train_info, _, _ = get_trained_model(\n",
    "            select_model,\n",
    "            device,\n",
    "        )\n",
    "        model = model.to(device)\n",
    "        model.eval()\n",
    "\n",
    "        setup = train_info.model_setup\n",
    "        iou_types = get_iou_types(model, setup)\n",
    "\n",
    "        dataset_params_dict = {\n",
    "            \"MIMIC_EYE_PATH\": MIMIC_EYE_PATH,\n",
    "            \"labels_cols\": setup.lesion_label_cols,\n",
    "            \"with_xrays_input\": SourceStrs.XRAYS in setup.sources,\n",
    "            \"with_clincal_input\": SourceStrs.CLINICAL in setup.sources,\n",
    "            \"with_fixations_input\": SourceStrs.FIXATIONS in setup.sources,\n",
    "            \"fiaxtions_mode_input\": setup.fiaxtions_mode_input,\n",
    "            \"with_bboxes_label\": TaskStrs.LESION_DETECTION in setup.tasks,\n",
    "            \"with_fixations_label\": TaskStrs.FIXATION_GENERATION in setup.tasks,\n",
    "            \"fiaxtions_mode_label\": setup.fiaxtions_mode_label,\n",
    "            \"with_chexpert_label\": TaskStrs.CHEXPERT_CLASSIFICATION in setup.tasks,\n",
    "            \"with_negbio_label\": TaskStrs.NEGBIO_CLASSIFICATION in setup.tasks,\n",
    "            \"clinical_numerical_cols\": setup.clinical_num,\n",
    "            \"clinical_categorical_cols\": setup.clinical_cat,\n",
    "            \"image_size\": setup.image_size,\n",
    "            \"image_mean\": setup.image_mean,\n",
    "            \"image_std\": setup.image_std,\n",
    "        }\n",
    "\n",
    "        detect_eval_dataset, train_dataset, val_dataset, test_dataset = get_datasets(\n",
    "            dataset_params_dict=dataset_params_dict,\n",
    "        )\n",
    "\n",
    "        train_dataloader, val_dataloader, test_dataloader = get_dataloaders(\n",
    "            train_dataset,\n",
    "            val_dataset,\n",
    "            test_dataset,\n",
    "            batch_size=setup.batch_size,\n",
    "        )\n",
    "\n",
    "        train_coco = None\n",
    "        train_coco, val_coco, test_coco, _ = get_coco_eval_params(\n",
    "            train_dataloader,\n",
    "            val_dataloader,\n",
    "            test_dataloader,\n",
    "            detect_eval_dataset,\n",
    "            setup.iou_thrs,\n",
    "            setup.use_iobb,\n",
    "        )\n",
    "\n",
    "        normal_range_eval_params_dict = get_eval_params_dict(\n",
    "            detect_eval_dataset,\n",
    "            iou_thrs=normal_iou_thrs,\n",
    "        )\n",
    "\n",
    "        all_cat_ids = [None] + [\n",
    "            detect_eval_dataset.disease_to_idx(d)\n",
    "            for d in detect_eval_dataset.labels_cols\n",
    "        ]\n",
    "\n",
    "        for cat_id in all_cat_ids:\n",
    "            cat_ids = (\n",
    "                [\n",
    "                    detect_eval_dataset.disease_to_idx(d)\n",
    "                    for d in detect_eval_dataset.labels_cols\n",
    "                ]\n",
    "                if cat_id is None\n",
    "                else [cat_id]\n",
    "            )\n",
    "\n",
    "            if not (cat_ids is None):\n",
    "                normal_range_eval_params_dict[\"bbox\"].catIds = cat_ids\n",
    "                normal_range_eval_params_dict[\"segm\"].catIds = cat_ids\n",
    "\n",
    "            test_evaluator, _ = evaluate(\n",
    "                setup=setup,\n",
    "                model=model,\n",
    "                data_loader=test_dataloader,\n",
    "                device=device,\n",
    "                params_dict=normal_range_eval_params_dict,\n",
    "                coco=test_coco,\n",
    "                iou_types=iou_types,\n",
    "                # score_thres=score_thres,\n",
    "            )\n",
    "\n",
    "            if cat_id is None:\n",
    "                disease_str = \"all\"\n",
    "            else:\n",
    "                disease_str = detect_eval_dataset.label_idx_to_disease(cat_id)\n",
    "\n",
    "            save_iou_results(\n",
    "                test_evaluator,\n",
    "                f\"test_{disease_str}_score_thrs{score_thrs}\",\n",
    "                select_model.value,\n",
    "            )\n",
    "\n",
    "            test_ap_ar = get_ap_ar(\n",
    "                test_evaluator,\n",
    "                areaRng=\"all\",\n",
    "                maxDets=10,\n",
    "                iouThr=None,\n",
    "            )\n",
    "\n",
    "            # test_ap_ar = get_ap_ar(\n",
    "            #     test_evaluator, areaRng=\"all\", maxDets=10, iouThr=0.5,\n",
    "            # )\n",
    "            # val_ap_ar = get_ap_ar(val_evaluator, areaRng=\"all\", maxDets=10, iouThr=0.5,)\n",
    "\n",
    "            df = pd.DataFrame(\n",
    "                [\n",
    "                    {\n",
    "                        f\"AP@[.50:.05:.95]\": test_ap_ar[\"ap\"],\n",
    "                        f\"AR@[.50:.05:.95]\": test_ap_ar[\"ar\"],\n",
    "                    },\n",
    "                ]\n",
    "            )\n",
    "\n",
    "            df.to_csv(\n",
    "                os.path.join(\n",
    "                    \"eval_results\",\n",
    "                    f\"{select_model.value}_{disease_str}_score_thrs{score_thrs}.csv\",\n",
    "                )\n",
    "            )\n",
    "\n",
    "            num_fps = get_num_fps(\n",
    "                test_evaluator,\n",
    "                areaRng=\"all\",\n",
    "                maxDets=10,\n",
    "                iouThr=0.5,\n",
    "            )\n",
    "\n",
    "            num_fns = get_num_fns(\n",
    "                test_evaluator,\n",
    "                areaRng=\"all\",\n",
    "                maxDets=10,\n",
    "                iouThr=0.5,\n",
    "            )\n",
    "\n",
    "            num_tps = get_num_tps(\n",
    "                test_evaluator,\n",
    "                areaRng=\"all\",\n",
    "                maxDets=10,\n",
    "                iouThr=0.5,\n",
    "            )\n",
    "\n",
    "            confusion_df = pd.DataFrame(\n",
    "                [\n",
    "                    {\n",
    "                        \"num_fps\": num_fps,\n",
    "                        \"num_fns\": num_fns,\n",
    "                        \"num_tps\": num_tps,\n",
    "                    },\n",
    "                ]\n",
    "            )\n",
    "\n",
    "            confusion_df.to_csv(\n",
    "                os.path.join(\n",
    "                    \"eval_results\",\n",
    "                    f\"{select_model.value}_{disease_str}_score_thrs{score_thrs}_confusion.csv\",\n",
    "                )\n",
    "            )\n",
    "\n",
    "            print_title(disease_str)\n",
    "            print(df)\n",
    "            print(confusion_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "52a48fdedee40b77eb251917c5aa239bf02f1ab8c93cc13fe7347f570eadc6b9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
