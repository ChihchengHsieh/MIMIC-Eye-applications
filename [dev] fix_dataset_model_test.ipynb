{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This notebook will running on device: [CUDA]\n"
     ]
    }
   ],
   "source": [
    "from utils.init import reproducibility, clean_memory_get_device\n",
    "\n",
    "device = clean_memory_get_device()\n",
    "reproducibility()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|===========================================================================|\n",
      "|                  PyTorch CUDA memory summary, device ID 0                 |\n",
      "|---------------------------------------------------------------------------|\n",
      "|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n",
      "|===========================================================================|\n",
      "|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocated memory      |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active memory         |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved memory   |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable memory |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocations           |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active allocs         |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved segments |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable allocs |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Oversize allocations  |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Oversize GPU segments |       0    |       0    |       0    |       0    |\n",
      "|===========================================================================|\n",
      "\n",
      "|===========================================================================|\n",
      "|                  PyTorch CUDA memory summary, device ID 0                 |\n",
      "|---------------------------------------------------------------------------|\n",
      "|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n",
      "|===========================================================================|\n",
      "|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocated memory      |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active memory         |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved memory   |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable memory |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocations           |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active allocs         |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved segments |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable allocs |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Oversize allocations  |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Oversize GPU segments |       0    |       0    |       0    |       0    |\n",
      "|===========================================================================|\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from data.transforms import get_tensorise_h_flip_transform\n",
    "from data.constants import DEFAULT_REFLACX_LABEL_COLS\n",
    "from data.paths import MIMIC_EYE_PATH\n",
    "from data.datasets import ReflacxObjectDetectionWithFixations\n",
    "from torch.utils.data import DataLoader\n",
    "from data.datasets import collate_fn\n",
    "from data.load import seed_worker, get_dataloader_g\n",
    "import torch\n",
    "\n",
    "print(torch.cuda.memory_summary())\n",
    "\n",
    "dataset_params_dict = {\n",
    "    \"MIMIC_EYE_PATH\": MIMIC_EYE_PATH,\n",
    "    # \"with_clinical\": model_setup.use_clinical,\n",
    "    \"bbox_to_mask\": False,\n",
    "    \"labels_cols\": DEFAULT_REFLACX_LABEL_COLS,\n",
    "}\n",
    "\n",
    "train_dataset = ReflacxObjectDetectionWithFixations(\n",
    "        **dataset_params_dict, split_str=\"train\", transforms=get_tensorise_h_flip_transform(train=False), with_fixations=True\n",
    ")\n",
    "\n",
    "train_dataloader =  DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=4,\n",
    "    shuffle=True,\n",
    "    collate_fn=collate_fn,\n",
    "    worker_init_fn=seed_worker,\n",
    "    generator=get_dataloader_g(0),\n",
    ")\n",
    "print(torch.cuda.memory_summary())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.components.feature_extractors import ImageFeatureExtractor\n",
    "from models.components.fusors import NoActionFusor\n",
    "from models.components.task_performers import ObjectDetectionParameters, ObjectDetectionPerformer, HeatmapGeneratorParameters, HeatmapGenerator\n",
    "from models.frameworks import ExtractFusePerform\n",
    "from models.backbones import get_normal_backbone\n",
    "from models.setup import ModelSetup\n",
    "from data.constants import DEFAULT_REFLACX_LABEL_COLS\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using pretrained backbone. mobilenet_v3\n",
      "|===========================================================================|\n",
      "|                  PyTorch CUDA memory summary, device ID 0                 |\n",
      "|---------------------------------------------------------------------------|\n",
      "|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n",
      "|===========================================================================|\n",
      "|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocated memory      |   22419 KB |   22419 KB |   22419 KB |       0 B  |\n",
      "|       from large pool |   17936 KB |   17936 KB |   17936 KB |       0 B  |\n",
      "|       from small pool |    4483 KB |    4483 KB |    4483 KB |       0 B  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active memory         |   22419 KB |   22419 KB |   22419 KB |       0 B  |\n",
      "|       from large pool |   17936 KB |   17936 KB |   17936 KB |       0 B  |\n",
      "|       from small pool |    4483 KB |    4483 KB |    4483 KB |       0 B  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved memory   |   26624 KB |   26624 KB |   26624 KB |       0 B  |\n",
      "|       from large pool |   20480 KB |   20480 KB |   20480 KB |       0 B  |\n",
      "|       from small pool |    6144 KB |    6144 KB |    6144 KB |       0 B  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable memory |    4204 KB |   19551 KB |   24858 KB |   20653 KB |\n",
      "|       from large pool |    2544 KB |   19184 KB |   19184 KB |   16640 KB |\n",
      "|       from small pool |    1660 KB |    2046 KB |    5674 KB |    4013 KB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocations           |     326    |     326    |     326    |       0    |\n",
      "|       from large pool |       3    |       3    |       3    |       0    |\n",
      "|       from small pool |     323    |     323    |     323    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active allocs         |     326    |     326    |     326    |       0    |\n",
      "|       from large pool |       3    |       3    |       3    |       0    |\n",
      "|       from small pool |     323    |     323    |     323    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved segments |       4    |       4    |       4    |       0    |\n",
      "|       from large pool |       1    |       1    |       1    |       0    |\n",
      "|       from small pool |       3    |       3    |       3    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable allocs |       2    |       3    |       4    |       2    |\n",
      "|       from large pool |       1    |       1    |       1    |       0    |\n",
      "|       from small pool |       1    |       2    |       3    |       2    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Oversize allocations  |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Oversize GPU segments |       0    |       0    |       0    |       0    |\n",
      "|===========================================================================|\n",
      "\n"
     ]
    }
   ],
   "source": [
    "setup = ModelSetup(image_size=256)\n",
    "backbone = get_normal_backbone(setup)\n",
    "image_extractor = ImageFeatureExtractor(backbone)\n",
    "fusor = NoActionFusor()\n",
    "\n",
    "\n",
    "obj_params = ObjectDetectionParameters(image_size=setup.image_size)\n",
    "obj_performer = ObjectDetectionPerformer(\n",
    "    obj_params,\n",
    "    image_extractor.backbone.out_channels,\n",
    "    len(DEFAULT_REFLACX_LABEL_COLS) + 1\n",
    ")\n",
    "\n",
    "fix_params = HeatmapGeneratorParameters(input_channel=backbone.out_channels, decoder_channels=[64, 32, 16, 8, 1 ]) # the output should be just one channel.\n",
    "fix_performer = HeatmapGenerator(\n",
    "    params= fix_params,\n",
    ")\n",
    "\n",
    "model = ExtractFusePerform(\n",
    "    feature_extractors=nn.ModuleDict({\"image\": image_extractor}),\n",
    "    fusor=fusor,\n",
    "    task_performers=nn.ModuleDict({\"object-detection\": obj_performer, \"fixation-generation\": fix_performer }),\n",
    ")\n",
    "model.to(device)\n",
    "\n",
    "print(torch.cuda.memory_summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_dict_elements_to_device(x, device):\n",
    "    for k in x.keys():\n",
    "        try:\n",
    "            x[k] = x[k].to(device) \n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mike8\\Document\\GitHub\\MIMIC-Eye-applications\\data\\datasets.py:437: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  boxes_df[k] = ellipse_df[\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after preparation, the size is torch.Size([1, 256, 256])\n",
      "|===========================================================================|\n",
      "|                  PyTorch CUDA memory summary, device ID 0                 |\n",
      "|---------------------------------------------------------------------------|\n",
      "|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n",
      "|===========================================================================|\n",
      "|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocated memory      |   25753 KB |   25753 KB |   25753 KB |       0 B  |\n",
      "|       from large pool |   21008 KB |   21008 KB |   21008 KB |       0 B  |\n",
      "|       from small pool |    4745 KB |    4745 KB |    4745 KB |       0 B  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active memory         |   25753 KB |   25753 KB |   25753 KB |       0 B  |\n",
      "|       from large pool |   21008 KB |   21008 KB |   21008 KB |       0 B  |\n",
      "|       from small pool |    4745 KB |    4745 KB |    4745 KB |       0 B  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved memory   |   47104 KB |   47104 KB |   47104 KB |       0 B  |\n",
      "|       from large pool |   40960 KB |   40960 KB |   40960 KB |       0 B  |\n",
      "|       from small pool |    6144 KB |    6144 KB |    6144 KB |       0 B  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable memory |   21350 KB |   21612 KB |   42266 KB |   20915 KB |\n",
      "|       from large pool |   19952 KB |   19952 KB |   36592 KB |   16640 KB |\n",
      "|       from small pool |    1398 KB |    2046 KB |    5674 KB |    4275 KB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocations           |     343    |     343    |     343    |       0    |\n",
      "|       from large pool |       4    |       4    |       4    |       0    |\n",
      "|       from small pool |     339    |     339    |     339    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active allocs         |     343    |     343    |     343    |       0    |\n",
      "|       from large pool |       4    |       4    |       4    |       0    |\n",
      "|       from small pool |     339    |     339    |     339    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved segments |       5    |       5    |       5    |       0    |\n",
      "|       from large pool |       2    |       2    |       2    |       0    |\n",
      "|       from small pool |       3    |       3    |       3    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable allocs |       3    |       3    |       5    |       2    |\n",
      "|       from large pool |       2    |       2    |       2    |       0    |\n",
      "|       from small pool |       1    |       2    |       3    |       2    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Oversize allocations  |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Oversize GPU segments |       0    |       0    |       0    |       0    |\n",
      "|===========================================================================|\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = next(iter(train_dataloader))\n",
    "inputs, targets = train_dataset.prepare_input_from_data(data)\n",
    "inputs, targets = model.prepare(inputs, targets)\n",
    "inputs = map_dict_elements_to_device(inputs, device)\n",
    "targets = [ map_dict_elements_to_device(t, device) for t in targets]\n",
    "\n",
    "print(torch.cuda.memory_summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mike8\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\functional.py:1320: UserWarning: dropout2d: Received a 2-D input to dropout2d, which is deprecated and will result in an error in a future release. To retain the behavior and silence this warning, please use dropout instead. Note that dropout2d exists to provide channel-wise dropout on inputs with 2 spatial dimensions, a channel dimension, and an optional batch dimension (i.e. 3D or 4D inputs).\n",
      "  warnings.warn(warn_msg)\n"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "outputs = model(inputs, targets=targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "52a48fdedee40b77eb251917c5aa239bf02f1ab8c93cc13fe7347f570eadc6b9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
