{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import utils.print as print_f\n",
    "import os\n",
    "\n",
    "from utils.engine import evaluate, get_iou_types\n",
    "from utils.plot import plot_losses, plot_ap_ars, plot_performance\n",
    "from data.strs import TaskStrs, SourceStrs, FusionStrs\n",
    "\n",
    "from models.utils import get_model_size_in_MB\n",
    "from models.build import create_model_from_setup\n",
    "from models.setup import ModelSetup\n",
    "from models.train import TrainingInfo\n",
    "from utils.save import check_best, end_train, get_data_from_metric_logger\n",
    "from data.load import get_datasets, get_dataloaders\n",
    "from IPython.display import clear_output\n",
    "from utils.eval import get_ap_ar, get_ap_ar_for_train_val, get_performance\n",
    "from utils.train import get_optimiser, get_lr_scheduler, print_params_setup, get_coco_eval_params, get_dynamic_loss\n",
    "from utils.init import reproducibility, clean_memory_get_device\n",
    "from data.paths import MIMIC_EYE_PATH\n",
    "# from datetime import datetime\n",
    "# from models.dynamic_loss import DynamicWeightedLoss\n",
    "from utils.engine import train_one_epoch, evaluate\n",
    "from torch import optim\n",
    "from models.setup import ModelSetup\n",
    "from data.paths import MIMIC_EYE_PATH\n",
    "# from data.load import seed_worker, get_dataloader_g\n",
    "\n",
    "## Suppress the assignement warning from pandas.r\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "\n",
    "## Supress user warning\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from models.components.task_performers import ObjectDetectionPerformer\n",
    "from data.constants import DEFAULT_MIMIC_CLINICAL_NUM_COLS, DEFAULT_MIMIC_CLINICAL_CAT_COLS\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"max_split_size_mb:256\"\n",
    "# 'PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:512'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This notebook will running on device: [CUDA]\n"
     ]
    }
   ],
   "source": [
    "device = clean_memory_get_device()\n",
    "reproducibility()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|===========================================================================|\n",
      "|                  PyTorch CUDA memory summary, device ID 0                 |\n",
      "|---------------------------------------------------------------------------|\n",
      "|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n",
      "|===========================================================================|\n",
      "|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocated memory      |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active memory         |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved memory   |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable memory |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocations           |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active allocs         |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved segments |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable allocs |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Oversize allocations  |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Oversize GPU segments |       0    |       0    |       0    |       0    |\n",
      "|===========================================================================|\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.memory_summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_args = {\n",
    "    # \"sources\": [SourceStrs.XRAYS],\n",
    "    # \"sources\": [SourceStrs.XRAYS, SourceStrs.CLINICAL,],\n",
    "    # \"tasks\": [\n",
    "    #     # TaskStrs.LESION_DETECTION,\n",
    "    #     TaskStrs.FIXATION_GENERATION,\n",
    "    #     TaskStrs.CHEXPERT_CLASSIFICATION,\n",
    "    #     # TaskStrs.NEGBIO_CLASSIFICATION,\n",
    "    # ],\n",
    "    # \"tasks\": [\n",
    "    #     # TaskStrs.LESION_DETECTION,\n",
    "    #     TaskStrs.FIXATION_GENERATION,\n",
    "    #     TaskStrs.CHEXPERT_CLASSIFICATION,\n",
    "    #     TaskStrs.NEGBIO_CLASSIFICATION,\n",
    "    # ],\n",
    "    \"performance_standard_task\": TaskStrs.CHEXPERT_CLASSIFICATION,\n",
    "    \"performance_standard_metric\": \"auc\",\n",
    "\n",
    "    # \"performance_standard_task\": TaskStrs.LESION_DETECTION,\n",
    "    # \"performance_standard_metric\": \"ap\",\n",
    "\n",
    "    \"decoder_channels\": [128, 64, 32, 16, 1],\n",
    "    \"optimiser\": \"sgd\",\n",
    "    \"lr\": 1e-3,  # should multiply by 8 or just use 1e-2, to test if it will explode.\n",
    "    \"batch_size\": 16,\n",
    "    \"weight_decay\": 1e-9,  # 1E-5\n",
    "    # \"pretrained\": True,\n",
    "    \"record_training_performance\": True,\n",
    "    \"image_size\": 512,\n",
    "    \"warmup_epochs\": 0,\n",
    "    \"lr_scheduler\": \"ReduceLROnPlateau\",\n",
    "    \"reduceLROnPlateau_factor\": 0.1,\n",
    "    \"reduceLROnPlateau_patience\": 999,\n",
    "    \"reduceLROnPlateau_full_stop\": True,\n",
    "    \"multiStepLR_milestones\": 100,\n",
    "    \"multiStepLR_gamma\": 0.1,\n",
    "    \"use_mask\": False,\n",
    "    \"gt_in_train_till\": 0,\n",
    "    \"box_head_dropout_rate\": 0,\n",
    "    \"measure_test\": True,\n",
    "    \"fiaxtions_mode\": \"reporting\",\n",
    "}\n",
    "\n",
    "with_fix_args= {\n",
    "    \"sources\": [SourceStrs.XRAYS],\n",
    "    # \"sources\": [SourceStrs.XRAYS, SourceStrs.CLINICAL,],\n",
    "    \"tasks\": [\n",
    "        # TaskStrs.LESION_DETECTION,\n",
    "        TaskStrs.FIXATION_GENERATION,\n",
    "        TaskStrs.CHEXPERT_CLASSIFICATION,\n",
    "        # TaskStrs.NEGBIO_CLASSIFICATION,\n",
    "    ],\n",
    "}\n",
    "\n",
    "without_fix_args= {\n",
    "    \"sources\": [SourceStrs.XRAYS],\n",
    "    # \"sources\": [SourceStrs.XRAYS, SourceStrs.CLINICAL,],\n",
    "    \"tasks\": [\n",
    "        # TaskStrs.LESION_DETECTION,\n",
    "        # TaskStrs.FIXATION_GENERATION,\n",
    "        TaskStrs.CHEXPERT_CLASSIFICATION,\n",
    "        # TaskStrs.NEGBIO_CLASSIFICATION,\n",
    "    ],\n",
    "}\n",
    "\n",
    "small_model_args = {\n",
    "    \"mask_hidden_layers\": 64,\n",
    "    \"fuse_conv_channels\": 64,\n",
    "    \"representation_size\": 64,  # 32\n",
    "    # \"clinical_input_channels\": 64,\n",
    "    # \"clinical_conv_channels\": 64,\n",
    "    # \"clinical_expand_conv_channels\": 64,\n",
    "    \"backbone_out_channels\": 64,\n",
    "}\n",
    "\n",
    "mobilenet_args = {\n",
    "    \"backbone\": \"mobilenet_v3\",\n",
    "    \"using_fpn\": False,\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_model_setups = [\n",
    "    # ModelSetup(\n",
    "    #     name=\"chexpert_with_fix\",\n",
    "    #     **mobilenet_args,\n",
    "    #     **small_model_args,\n",
    "    #     **common_args,\n",
    "    #     **with_fix_args\n",
    "    # ),\n",
    "    ModelSetup(\n",
    "        name=\"chexpert_without_fix\",\n",
    "        **mobilenet_args,\n",
    "        **small_model_args,\n",
    "        **common_args,\n",
    "        **without_fix_args\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 30\n",
    "train_infos = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'AxesSubplot' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_4060/2509288891.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    298\u001b[0m         \u001b[1;31m# if model_setup.record_training_performance:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    299\u001b[0m         \u001b[1;31m# plot all matrics\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 300\u001b[1;33m         plot_performance(\n\u001b[0m\u001b[0;32m    301\u001b[0m             \u001b[0mperformance\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain_info\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mperformance\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    302\u001b[0m             \u001b[0mall_tasks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain_info\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mall_tasks\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\mike8\\Document\\GitHub\\MIMIC-Eye-applications\\utils\\plot.py\u001b[0m in \u001b[0;36mplot_performance\u001b[1;34m(performance, all_tasks, fig_title)\u001b[0m\n\u001b[0;32m    351\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mp_list\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    352\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mp_list\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 353\u001b[1;33m                     \u001b[0maxes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0maxes_idx_map\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34mf\"{t}_{k}\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_title\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"{t}_{k}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    354\u001b[0m                     axes[axes_idx_map[f\"{t}_{k}\"]].plot(\n\u001b[0;32m    355\u001b[0m                         \u001b[0mv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmarker\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"o\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msplit_to_colour\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'AxesSubplot' object is not subscriptable"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x400 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# we have to mention that in order to provide objective evaluation, we compromise the dataset size, which also nagatively afftect the performance and generlaization.\n",
    "\n",
    "for setup in all_model_setups:\n",
    "    assert (\n",
    "        len(setup.sources) > 0 and len(setup.tasks) > 0\n",
    "    ), \"Need at least one source and task.\"\n",
    "\n",
    "    print_f.print_title(\"Preparing for the training.\")\n",
    "\n",
    "    train_info = TrainingInfo(setup)\n",
    "\n",
    "    # if setup.measure_test:\n",
    "    #     # initialise the test recording list.\n",
    "    #     train_info.test_ap_ars = []\n",
    "\n",
    "    model = create_model_from_setup(setup=setup)\n",
    "    model = model.to(device)\n",
    "\n",
    "    train_info.all_tasks = list(model.task_performers.keys())\n",
    "    print(f\" Model Size [{get_model_size_in_MB(model):.3f}] MB\")\n",
    "\n",
    "    ################ Datasets ################\n",
    "    dataset_params_dict = {\n",
    "        \"MIMIC_EYE_PATH\": MIMIC_EYE_PATH,\n",
    "        \"labels_cols\": setup.lesion_label_cols,\n",
    "        \"with_clincal\": SourceStrs.CLINICAL in setup.sources,\n",
    "        \"with_xrays\": SourceStrs.XRAYS in setup.sources,\n",
    "        \"with_bboxes\": TaskStrs.LESION_DETECTION in setup.tasks,\n",
    "        \"with_fixations\": TaskStrs.FIXATION_GENERATION in setup.tasks,\n",
    "        \"with_chexpert\": TaskStrs.CHEXPERT_CLASSIFICATION in setup.tasks,\n",
    "        \"with_negbio\": TaskStrs.NEGBIO_CLASSIFICATION in setup.tasks,\n",
    "        \"fiaxtions_mode\": setup.fiaxtions_mode,\n",
    "        \"clinical_numerical_cols\": setup.clinical_num,\n",
    "        \"clinical_categorical_cols\": setup.clinical_cat,\n",
    "    }\n",
    "\n",
    "    detect_eval_dataset, train_dataset, val_dataset, test_dataset = get_datasets(\n",
    "        dataset_params_dict=dataset_params_dict,\n",
    "    )\n",
    "\n",
    "    train_dataloader, val_dataloader, test_dataloader = get_dataloaders(\n",
    "        train_dataset, val_dataset, test_dataset, batch_size=setup.batch_size,\n",
    "    )\n",
    "\n",
    "    train_coco = None\n",
    "    val_coco = None\n",
    "    test_coco = None\n",
    "    eval_params_dict = None\n",
    "\n",
    "    if TaskStrs.LESION_DETECTION in setup.tasks:\n",
    "        train_coco, val_coco, test_coco, eval_params_dict = get_coco_eval_params(\n",
    "            source_name=SourceStrs.XRAYS,\n",
    "            task_name=TaskStrs.LESION_DETECTION,\n",
    "            train_dataloader=train_dataloader,\n",
    "            val_dataloader=val_dataloader,\n",
    "            test_dataloader=test_dataloader,\n",
    "            detect_eval_dataset=detect_eval_dataset,\n",
    "            iou_thrs=setup.iou_thrs,\n",
    "            use_iobb=setup.use_iobb,\n",
    "        )\n",
    "\n",
    "    train_info.timer.start_training()\n",
    "\n",
    "    dynamic_loss_weight = get_dynamic_loss(\n",
    "        loss_keys=model.get_all_losses_keys(), device=device\n",
    "    )\n",
    "    params = model.get_all_params(dynamic_loss_weight=dynamic_loss_weight)\n",
    "\n",
    "    iou_types = get_iou_types(model, setup)\n",
    "    optimizer = get_optimiser(params, setup)\n",
    "    lr_scheduler = get_lr_scheduler(optimizer, setup)\n",
    "\n",
    "    print_f.print_title(\n",
    "        f\"Start training. Preparing Took [{train_info.timer.has_took_sec_from_init()}] sec\"\n",
    "    )\n",
    "\n",
    "    train_info.timer.start_training()\n",
    "\n",
    "    val_loss = None\n",
    "\n",
    "    # Start the training from here.\n",
    "    for e in range(1, num_epochs + 1):\n",
    "\n",
    "        print_f.print_title(f\"Training model: [{setup.name}]\")\n",
    "\n",
    "        print(train_info)\n",
    "\n",
    "        train_info.epoch = e\n",
    "\n",
    "        train_info.timer.start_epoch()\n",
    "\n",
    "        if (\n",
    "            any(\n",
    "                [\n",
    "                    isinstance(p, ObjectDetectionPerformer)\n",
    "                    for p in model.task_performers.values()\n",
    "                ]\n",
    "            )\n",
    "            and train_info.epoch > setup.gt_in_train_till\n",
    "        ):\n",
    "            model.task_performers[\n",
    "                TaskStrs.LESION_DETECTION\n",
    "            ].roi_heads.use_gt_in_train = False\n",
    "\n",
    "        ###### Perform training and show the training result here ######\n",
    "        model.train()\n",
    "\n",
    "        train_info.last_train_evaluator, train_loger = train_one_epoch(\n",
    "            setup=setup,\n",
    "            model=model,\n",
    "            optimizer=optimizer,\n",
    "            data_loader=train_dataloader,\n",
    "            # data_loader=test_dataloader,\n",
    "            device=device,\n",
    "            epoch=train_info.epoch,\n",
    "            print_freq=10,\n",
    "            iou_types=iou_types,\n",
    "            coco=train_coco,\n",
    "            score_thres=None,\n",
    "            evaluate_on_run=True,\n",
    "            params_dict=eval_params_dict,\n",
    "            dynamic_loss_weight=dynamic_loss_weight,\n",
    "        )\n",
    "\n",
    "        # train_info.train_evaluators.append(train_evaluator)\n",
    "        train_info.train_losses.append(get_data_from_metric_logger(train_loger))\n",
    "        ################################################################\n",
    "\n",
    "        ####### Put the model into evaluation mode, start evaluating the current model #######\n",
    "        model.eval()\n",
    "\n",
    "        train_info.last_val_evaluator, val_logger = evaluate(\n",
    "            setup=setup,\n",
    "            model=model,\n",
    "            data_loader=val_dataloader,\n",
    "            device=device,\n",
    "            params_dict=eval_params_dict,\n",
    "            coco=val_coco,\n",
    "            iou_types=iou_types,\n",
    "            score_thres=None,\n",
    "        )\n",
    "\n",
    "        # train_info.val_evaluators.append(val_evaluator)\n",
    "        train_info.val_losses.append(get_data_from_metric_logger(val_logger))\n",
    "\n",
    "        train_info.performance[\"train\"].append(\n",
    "            get_performance(\n",
    "                train_info.all_tasks,\n",
    "                train_info.last_train_evaluator,\n",
    "                iouThr=0.5,\n",
    "                areaRng=\"all\",\n",
    "                maxDets=10,\n",
    "            )\n",
    "        )\n",
    "\n",
    "        # train_ap_ar, val_ap_ar = get_ap_ar_for_train_val(\n",
    "        #     train_info.last_train_evaluator[TaskStrs.LESION_DETECTION],\n",
    "        #     train_info.last_val_evaluator[TaskStrs.LESION_DETECTION],\n",
    "        #     areaRng=\"all\",\n",
    "        #     iouThr=0.5,\n",
    "        #     maxDets=10,\n",
    "        # )\n",
    "\n",
    "        # train_info.performance[\"train\"].append(\n",
    "        #     {\n",
    "        #         \"lesion-detection\": train_ap_ar,\n",
    "        #         \"fixation-generation\": {\n",
    "        #             \"iou\": train_info.last_train_evaluator[\n",
    "        #                 \"fixation-generation\"\n",
    "        #             ].get_iou()\n",
    "        #         },\n",
    "        #         \"chexpert-classification\": {\n",
    "        #             \"auc\": train_info.last_train_evaluator[\n",
    "        #                 \"chexpert-classification\"\n",
    "        #             ].get_clf_score(roc_auc_score)\n",
    "        #         },\n",
    "        #         \"negbio-classification\": {\n",
    "        #             \"auc\": train_info.last_train_evaluator[\n",
    "        #                 \"negbio-classification\"\n",
    "        #             ].get_clf_score(roc_auc_score)\n",
    "        #         },\n",
    "        #     }\n",
    "        # )\n",
    "\n",
    "        train_info.performance[\"val\"].append(\n",
    "            get_performance(\n",
    "                train_info.all_tasks,\n",
    "                train_info.last_val_evaluator,\n",
    "                iouThr=0.5,\n",
    "                areaRng=\"all\",\n",
    "                maxDets=10,\n",
    "            )\n",
    "        )\n",
    "\n",
    "        # train_info.performance[\"val\"].append(\n",
    "        #     {\n",
    "        #         \"lesion-detection\": val_ap_ar,\n",
    "        #         \"fixation-generation\": {\n",
    "        #             \"iou\": train_info.last_val_evaluator[\n",
    "        #                 \"fixation-generation\"\n",
    "        #             ].get_iou()\n",
    "        #         },\n",
    "        #         \"chexpert-classification\": {\n",
    "        #             \"auc\": train_info.last_val_evaluator[\n",
    "        #                 \"chexpert-classification\"\n",
    "        #             ].get_clf_score(roc_auc_score)\n",
    "        #         },\n",
    "        #         \"negbio-classification\": {\n",
    "        #             \"auc\": train_info.last_val_evaluator[\n",
    "        #                 \"negbio-classification\"\n",
    "        #             ].get_clf_score(roc_auc_score)\n",
    "        #         },\n",
    "        #     }\n",
    "        # )\n",
    "\n",
    "        # train_info.train_ap_ars.append(train_ap_ar)\n",
    "        # train_info.val_ap_ars.append(val_ap_ar)\n",
    "\n",
    "        if setup.measure_test:\n",
    "            train_info.test_evaluator, test_logger = evaluate(\n",
    "                setup=setup,\n",
    "                model=model,\n",
    "                data_loader=test_dataloader,\n",
    "                device=device,\n",
    "                params_dict=eval_params_dict,\n",
    "                coco=test_coco,\n",
    "                iou_types=iou_types,\n",
    "                score_thres=None,\n",
    "            )\n",
    "            train_info.test_losses.append(get_data_from_metric_logger(test_logger))\n",
    "\n",
    "            # test_ap_ar = get_ap_ar(\n",
    "            #     train_info.test_evaluator[\"lesion-detection\"],\n",
    "            #     areaRng=\"all\",\n",
    "            #     iouThr=0.5,\n",
    "            #     maxDets=10,\n",
    "            # )\n",
    "            # train_info.test_ap_ars.append(test_ap_ar)\n",
    "\n",
    "            train_info.performance[\"test\"].append(\n",
    "                get_performance(\n",
    "                    train_info.all_tasks,\n",
    "                    train_info.test_evaluator,\n",
    "                    iouThr=0.5,\n",
    "                    areaRng=\"all\",\n",
    "                    maxDets=10,\n",
    "                )\n",
    "            )\n",
    "\n",
    "            # train_info.performance[\"test\"].append(\n",
    "            #     {\n",
    "            #         \"lesion-detection\": test_ap_ar,\n",
    "            #         \"fixation-generation\": {\n",
    "            #             \"iou\": train_info.test_evaluator[\n",
    "            #                 \"fixation-generation\"\n",
    "            #             ].get_iou()\n",
    "            #         },\n",
    "            #         \"chexpert-classification\": {\n",
    "            #             \"auc\": train_info.test_evaluator[\n",
    "            #                 \"chexpert-classification\"\n",
    "            #             ].get_clf_score(roc_auc_score)\n",
    "            #         },\n",
    "            #         \"negbio-classification\": {\n",
    "            #             \"auc\": train_info.test_evaluator[\n",
    "            #                 \"negbio-classification\"\n",
    "            #             ].get_clf_score(roc_auc_score)\n",
    "            #         },\n",
    "            #     }\n",
    "            # )\n",
    "\n",
    "        # update the learning rate\n",
    "\n",
    "        val_loss = train_info.val_losses[-1][\"loss\"]\n",
    "\n",
    "        epoch_took, sec_already_took, speed = train_info.timer.end_epoch(\n",
    "            train_info.epoch\n",
    "        )\n",
    "\n",
    "        if train_info.epoch > setup.warmup_epochs:\n",
    "            if not lr_scheduler is None:\n",
    "                if isinstance(lr_scheduler, optim.lr_scheduler.ReduceLROnPlateau):\n",
    "                    if (\n",
    "                        setup.reduceLROnPlateau_full_stop\n",
    "                        and lr_scheduler.num_bad_epochs\n",
    "                        >= setup.reduceLROnPlateau_patience\n",
    "                    ):\n",
    "                        print_f.print_title(\n",
    "                            f\"| EarlyStop | Epoch [{train_info.epoch}] Done | It has took [{sec_already_took/60:.2f}] min, Avg time: [{speed:.2f}] sec/epoch | Estimate time for [{num_epochs}] epochs: [{speed*num_epochs/60:.2f}] min | Epoch took [{epoch_took.seconds}] sec |\"\n",
    "                        )\n",
    "                        break\n",
    "                    lr_scheduler.step(val_loss)\n",
    "                else:\n",
    "                    lr_scheduler.step()\n",
    "\n",
    "        # Clean everything before we show the evaluating result in this stage, so we can inspect the training progress.\n",
    "        clear_output()\n",
    "\n",
    "        # if model_setup.record_training_performance:\n",
    "        # plot all matrics\n",
    "        plot_performance(\n",
    "            performance=train_info.performance,\n",
    "            all_tasks=train_info.all_tasks,\n",
    "            fig_title=\"Performance\",\n",
    "        )\n",
    "\n",
    "        plot_losses(\n",
    "            train_info.train_losses,\n",
    "            train_info.val_losses,\n",
    "            test_logers=train_info.test_losses,\n",
    "        )\n",
    "\n",
    "        # previous_time = current_time\n",
    "        # current_time = datetime.now()\n",
    "        # epoch_took = current_time - previous_time\n",
    "\n",
    "        # sec_took = (current_time - train_info.start_t).seconds\n",
    "        # speed = sec_took / train_info.epoch\n",
    "\n",
    "        print_str = f\"| Epoch [{train_info.epoch}] Done | It has took [{sec_already_took/60:.2f}] min, Avg time: [{speed:.2f}] sec/epoch | Estimate time for [{num_epochs}] epochs: [{speed*num_epochs/60:.2f}] min | Epoch took [{epoch_took.seconds}] sec | \"\n",
    "\n",
    "        if lr_scheduler and hasattr(lr_scheduler, \"num_bad_epochs\"):\n",
    "            print_str += f\"Patience [{lr_scheduler.num_bad_epochs}] |\"\n",
    "\n",
    "        print_f.print_title(print_str)\n",
    "\n",
    "        train_info\n",
    "\n",
    "        #######################################################################################\n",
    "        if setup.save_early_stop_model:\n",
    "            val_performance_value, train_info = check_best(\n",
    "                setup=setup,\n",
    "                val_performance_value=train_info.performance[\"val\"][-1][\n",
    "                    setup.performance_standard_task\n",
    "                ][setup.performance_standard_metric],\n",
    "                device=device,\n",
    "                eval_params_dict=eval_params_dict,\n",
    "                train_info=train_info,\n",
    "                model=model,\n",
    "                optim=optimizer,\n",
    "                test_dataloader=test_dataloader,\n",
    "                test_coco=test_coco,\n",
    "                iou_types=iou_types,\n",
    "                score_thres=None,\n",
    "                dynamic_weight=dynamic_loss_weight,\n",
    "            )\n",
    "\n",
    "    train_info = end_train(\n",
    "        setup=setup,\n",
    "        train_info=train_info,\n",
    "        model=model,\n",
    "        optim=optimizer,\n",
    "        eval_params_dict=eval_params_dict,\n",
    "        last_val_performance=train_info.performance[\"val\"][-1][\n",
    "            setup.performance_standard_task\n",
    "        ][setup.performance_standard_metric],\n",
    "        test_dataloader=test_dataloader,\n",
    "        device=device,\n",
    "        test_coco=test_coco,\n",
    "        iou_types=iou_types,\n",
    "        score_thres=None,\n",
    "        dynamic_weight=dynamic_loss_weight,\n",
    "    )\n",
    "\n",
    "    train_infos.append(train_info)\n",
    "\n",
    "\n",
    "# TODO: allow for any kind of pipeline.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_infos' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_21292/530910633.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mtrain_info\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtrain_infos\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_info\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     plot_performance(\n\u001b[0;32m      4\u001b[0m         \u001b[0mperformance\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain_info\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mperformance\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[0mall_tasks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain_info\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mall_tasks\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_infos' is not defined"
     ]
    }
   ],
   "source": [
    "for train_info in train_infos:\n",
    "    print(train_info)\n",
    "    plot_performance(\n",
    "        performance=train_info.performance,\n",
    "        all_tasks=train_info.all_tasks,\n",
    "        fig_title=\"Performance\",\n",
    "    )\n",
    "\n",
    "    plot_losses(\n",
    "        train_info.train_losses,\n",
    "        train_info.val_losses,\n",
    "        test_logers=train_info.test_losses,\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "52a48fdedee40b77eb251917c5aa239bf02f1ab8c93cc13fe7347f570eadc6b9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
