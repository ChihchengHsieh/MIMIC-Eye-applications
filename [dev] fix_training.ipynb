{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import utils.print as print_f\n",
    "import os\n",
    "\n",
    "from utils.engine import evaluate, get_iou_types\n",
    "from utils.plot import plot_losses, plot_performance\n",
    "from data.strs import TaskStrs, SourceStrs, FusionStrs\n",
    "\n",
    "from models.utils import get_model_size_in_MB\n",
    "from models.build import create_model_from_setup\n",
    "from models.setup import ModelSetup\n",
    "from models.train import TrainingInfo\n",
    "from utils.save import check_best, end_train, get_data_from_metric_logger\n",
    "from data.load import get_datasets, get_dataloaders\n",
    "from IPython.display import clear_output\n",
    "from utils.eval import get_ap_ar, get_ap_ar_for_train_val, get_performance\n",
    "from utils.train import get_optimiser, get_lr_scheduler, print_params_setup, get_coco_eval_params, get_dynamic_loss\n",
    "from utils.init import reproducibility, clean_memory_get_device\n",
    "from data.paths import MIMIC_EYE_PATH\n",
    "# from datetime import datetime\n",
    "# from models.dynamic_loss import DynamicWeightedLoss\n",
    "from utils.engine import train_one_epoch, evaluate\n",
    "from torch import optim\n",
    "from models.setup import ModelSetup\n",
    "from data.paths import MIMIC_EYE_PATH\n",
    "# from data.load import seed_worker, get_dataloader_g\n",
    "\n",
    "## Suppress the assignement warning from pandas.r\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "\n",
    "## Supress user warning\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from models.components.task_performers import ObjectDetectionPerformer\n",
    "from data.constants import DEFAULT_MIMIC_CLINICAL_NUM_COLS, DEFAULT_MIMIC_CLINICAL_CAT_COLS\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"max_split_size_mb:256\"\n",
    "# 'PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:512'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This notebook will running on device: [CPU]\n"
     ]
    }
   ],
   "source": [
    "device = clean_memory_get_device()\n",
    "reproducibility()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    print(torch.cuda.memory_summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_args = {\n",
    "    # \"sources\": [SourceStrs.XRAYS, SourceStrs.CLINICAL,],\n",
    "    # \"tasks\": [\n",
    "    #     # TaskStrs.LESION_DETECTION,\n",
    "    #     TaskStrs.FIXATION_GENERATION,\n",
    "    #     TaskStrs.CHEXPERT_CLASSIFICATION,\n",
    "    #     TaskStrs.NEGBIO_CLASSIFICATION,\n",
    "    # ],\n",
    "    \"performance_standard_task\": TaskStrs.CHEXPERT_CLASSIFICATION,\n",
    "    \"performance_standard_metric\": \"auc\",\n",
    "\n",
    "    # \"performance_standard_task\": TaskStrs.LESION_DETECTION,\n",
    "    # \"performance_standard_metric\": \"ap\",\n",
    "\n",
    "    \"decoder_channels\": [128, 64, 32, 16, 8],\n",
    "    \"optimiser\": \"sgd\",\n",
    "    \"lr\": 1e-3,  # should multiply by 8 or just use 1e-2, to test if it will explode.\n",
    "    \"batch_size\": 16,\n",
    "    \"weight_decay\": 1e-9,  # 1E-5\n",
    "    # \"pretrained\": True,\n",
    "    \"record_training_performance\": True,\n",
    "    \"image_size\": 512,\n",
    "    \"warmup_epochs\": 0,\n",
    "    \"lr_scheduler\": \"ReduceLROnPlateau\",\n",
    "    \"reduceLROnPlateau_factor\": 0.1,\n",
    "    \"reduceLROnPlateau_patience\": 999,\n",
    "    \"reduceLROnPlateau_full_stop\": True,\n",
    "    \"multiStepLR_milestones\": 100,\n",
    "    \"multiStepLR_gamma\": 0.1,\n",
    "    \"use_mask\": False,\n",
    "    \"gt_in_train_till\": 0,\n",
    "    \"box_head_dropout_rate\": 0,\n",
    "    \"measure_test\": True,\n",
    "    \"fiaxtions_mode\": \"reporting\",\n",
    "}\n",
    "\n",
    "with_fix_args= {\n",
    "    \"sources\": [SourceStrs.XRAYS],\n",
    "    # \"sources\": [SourceStrs.XRAYS, SourceStrs.CLINICAL,],\n",
    "    \"tasks\": [\n",
    "        # TaskStrs.LESION_DETECTION,\n",
    "        TaskStrs.FIXATION_GENERATION,\n",
    "        TaskStrs.CHEXPERT_CLASSIFICATION,\n",
    "        # TaskStrs.NEGBIO_CLASSIFICATION,\n",
    "    ],\n",
    "}\n",
    "\n",
    "without_fix_args= {\n",
    "    \"sources\": [SourceStrs.XRAYS],\n",
    "    # \"sources\": [SourceStrs.XRAYS, SourceStrs.CLINICAL,],\n",
    "    \"tasks\": [\n",
    "        # TaskStrs.LESION_DETECTION,\n",
    "        # TaskStrs.FIXATION_GENERATION,\n",
    "        TaskStrs.CHEXPERT_CLASSIFICATION,\n",
    "        # TaskStrs.NEGBIO_CLASSIFICATION,\n",
    "    ],\n",
    "}\n",
    "\n",
    "small_model_args = {\n",
    "    \"mask_hidden_layers\": 64,\n",
    "    \"fuse_conv_channels\": 64,\n",
    "    \"representation_size\": 64,  # 32\n",
    "    # \"clinical_input_channels\": 64,\n",
    "    # \"clinical_conv_channels\": 64,\n",
    "    # \"clinical_expand_conv_channels\": 64,\n",
    "    \"backbone_out_channels\": 64,\n",
    "}\n",
    "\n",
    "mobilenet_args = {\n",
    "    \"backbone\": \"mobilenet_v3\",\n",
    "    \"using_fpn\": False,\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_model_setups = [\n",
    "    ModelSetup(\n",
    "        name=\"chexpert_with_fix\",\n",
    "        **mobilenet_args,\n",
    "        **small_model_args,\n",
    "        **common_args,\n",
    "        **with_fix_args\n",
    "    ),\n",
    "    # ModelSetup(\n",
    "    #     name=\"chexpert_without_fix\",\n",
    "    #     **mobilenet_args,\n",
    "    #     **small_model_args,\n",
    "    #     **common_args,\n",
    "    #     **without_fix_args\n",
    "    # )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 1\n",
    "train_infos = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================Preparing for the training.====================\n",
      "Using pretrained backbone. mobilenet_v3\n",
      " Model Size [6.266] MB\n",
      "Using SGD as optimizer with lr=0.001\n",
      "====================Start training. Preparing Took [0] sec====================\n",
      "====================Training model: [chexpert_with_fix]====================\n",
      "========================================For Training [chexpert_with_fix]========================================\n",
      "ModelSetup(name='chexpert_with_fix', sources=['xrays'], tasks=['fixation-generation', 'chexpert-classification'], fusor='element-wise sum', decoder_channels=[128, 64, 32, 16, 8], lesion_label_cols=['Pulmonary edema', 'Enlarged cardiac silhouette', 'Consolidation', 'Atelectasis', 'Pleural abnormality'], save_early_stop_model=True, record_training_performance=True, backbone='mobilenet_v3', optimiser='sgd', lr=0.001, weight_decay=1e-09, image_backbone_pretrained=True, heatmap_backbone_pretrained=False, image_size=512, backbone_out_channels=64, batch_size=16, warmup_epochs=0, lr_scheduler='ReduceLROnPlateau', reduceLROnPlateau_factor=0.1, reduceLROnPlateau_patience=999, reduceLROnPlateau_full_stop=True, multiStepLR_milestones=100, multiStepLR_gamma=0.1, representation_size=64, mask_hidden_layers=64, using_fpn=False, use_mask=False, fuse_conv_channels=64, box_head_dropout_rate=0, fuse_depth=4, fusion_strategy='concat', fusion_residule=False, gt_in_train_till=0, measure_test=True, eval_freq=10, use_iobb=True, iou_thrs=array([0.5]), fiaxtions_mode='reporting', clinical_num=['age', 'temperature', 'heartrate', 'resprate', 'o2sat', 'sbp', 'dbp', 'acuity'], clinical_cat=['gender'], categorical_col_maps={'gender': 2}, clinical_cat_emb_dim=32, clinical_conv_channels=32, clinical_upsample='deconv', chexpert_label_cols=['Atelectasis_chexpert', 'Cardiomegaly_chexpert', 'Consolidation_chexpert', 'Edema_chexpert', 'Enlarged Cardiomediastinum_chexpert', 'Fracture_chexpert', 'Lung Lesion_chexpert', 'Lung Opacity_chexpert', 'No Finding_chexpert', 'Pleural Effusion_chexpert', 'Pleural Other_chexpert', 'Pneumonia_chexpert', 'Pneumothorax_chexpert', 'Support Devices_chexpert'], negbio_label_cols=['Atelectasis_negbio', 'Cardiomegaly_negbio', 'Consolidation_negbio', 'Edema_negbio', 'Enlarged Cardiomediastinum_negbio', 'Fracture_negbio', 'Lung Lesion_negbio', 'Lung Opacity_negbio', 'No Finding_negbio', 'Pleural Effusion_negbio', 'Pleural Other_negbio', 'Pneumonia_negbio', 'Pneumothorax_negbio', 'Support Devices_negbio'], performance_standard_task='chexpert-classification', performance_standard_metric='auc')\n",
      "================================================================================================================\n",
      "\n",
      "Best performance model has been saved to: [None]\n",
      "The final model has been saved to: [None]\n",
      "\n",
      "================================================================================================================\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [8], line 103\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[39m###### Perform training and show the training result here ######\u001b[39;00m\n\u001b[1;32m    101\u001b[0m model\u001b[39m.\u001b[39mtrain()\n\u001b[0;32m--> 103\u001b[0m train_info\u001b[39m.\u001b[39mlast_train_evaluator, train_loger \u001b[39m=\u001b[39m train_one_epoch(\n\u001b[1;32m    104\u001b[0m     setup\u001b[39m=\u001b[39;49msetup,\n\u001b[1;32m    105\u001b[0m     model\u001b[39m=\u001b[39;49mmodel,\n\u001b[1;32m    106\u001b[0m     optimizer\u001b[39m=\u001b[39;49moptimizer,\n\u001b[1;32m    107\u001b[0m     \u001b[39m# data_loader=train_dataloader,\u001b[39;49;00m\n\u001b[1;32m    108\u001b[0m     data_loader\u001b[39m=\u001b[39;49mtest_dataloader,\n\u001b[1;32m    109\u001b[0m     device\u001b[39m=\u001b[39;49mdevice,\n\u001b[1;32m    110\u001b[0m     epoch\u001b[39m=\u001b[39;49mtrain_info\u001b[39m.\u001b[39;49mepoch,\n\u001b[1;32m    111\u001b[0m     print_freq\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m,\n\u001b[1;32m    112\u001b[0m     iou_types\u001b[39m=\u001b[39;49miou_types,\n\u001b[1;32m    113\u001b[0m     coco\u001b[39m=\u001b[39;49mtrain_coco,\n\u001b[1;32m    114\u001b[0m     score_thres\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m    115\u001b[0m     evaluate_on_run\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    116\u001b[0m     params_dict\u001b[39m=\u001b[39;49meval_params_dict,\n\u001b[1;32m    117\u001b[0m     dynamic_loss_weight\u001b[39m=\u001b[39;49mdynamic_loss_weight,\n\u001b[1;32m    118\u001b[0m )\n\u001b[1;32m    120\u001b[0m \u001b[39m# train_info.train_evaluators.append(train_evaluator)\u001b[39;00m\n\u001b[1;32m    121\u001b[0m train_info\u001b[39m.\u001b[39mtrain_losses\u001b[39m.\u001b[39mappend(get_data_from_metric_logger(train_loger))\n",
      "File \u001b[0;32m~/Documents/GitHub/MIMIC-Eye-applications/utils/engine.py:242\u001b[0m, in \u001b[0;36mtrain_one_epoch\u001b[0;34m(setup, model, optimizer, data_loader, device, epoch, print_freq, iou_types, coco, score_thres, evaluate_on_run, params_dict, dynamic_loss_weight)\u001b[0m\n\u001b[1;32m    240\u001b[0m                 evaluators[k]\u001b[39m.\u001b[39mupdate(res)\n\u001b[1;32m    241\u001b[0m             \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 242\u001b[0m                 evaluators[k]\u001b[39m.\u001b[39;49mupdate(outputs[k][\u001b[39m\"\u001b[39;49m\u001b[39moutputs\u001b[39;49m\u001b[39m\"\u001b[39;49m], [\n\u001b[1;32m    243\u001b[0m                                      t[k] \u001b[39mfor\u001b[39;49;00m t \u001b[39min\u001b[39;49;00m targets])\n\u001b[1;32m    245\u001b[0m             model\u001b[39m.\u001b[39mevaluators \u001b[39m=\u001b[39m evaluators\n\u001b[1;32m    246\u001b[0m         \u001b[39m# raise StopIteration()\u001b[39;00m\n\u001b[1;32m    247\u001b[0m \n\u001b[1;32m    248\u001b[0m \u001b[39m# tasks to perform evaluation (fixation-generation, negbio-classification, chexpert-classification)\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[39m# iou_score = np.sum(intersection) / np.sum(union)\u001b[39;00m\n\u001b[1;32m    253\u001b[0m \u001b[39m# or accuracy\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/GitHub/MIMIC-Eye-applications/utils/engine.py:73\u001b[0m, in \u001b[0;36mHeatmapGenerationEvaluator.update\u001b[0;34m(self, outputs, targets)\u001b[0m\n\u001b[1;32m     71\u001b[0m gt \u001b[39m=\u001b[39m t[\u001b[39m'\u001b[39m\u001b[39mheatmaps\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mto(cpu_device)\u001b[39m.\u001b[39mdetach()\u001b[39m.\u001b[39mnumpy()\n\u001b[1;32m     72\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mious\u001b[39m.\u001b[39mappend(get_iou_score(gt\u001b[39m=\u001b[39mgt, pred\u001b[39m=\u001b[39mpred))\n\u001b[0;32m---> 73\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprecisions\u001b[39m.\u001b[39mappend(precision_score(\n\u001b[1;32m     74\u001b[0m     np\u001b[39m.\u001b[39;49marray(gt)\u001b[39m.\u001b[39;49mreshape(\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m), (np\u001b[39m.\u001b[39;49marray(pred) \u001b[39m>\u001b[39;49m \u001b[39m0.5\u001b[39;49m)\u001b[39m.\u001b[39;49mreshape(\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m)))\n\u001b[1;32m     75\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maccuracies\u001b[39m.\u001b[39mappend(accuracy_score(\n\u001b[1;32m     76\u001b[0m     np\u001b[39m.\u001b[39marray(gt)\u001b[39m.\u001b[39mreshape(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m), (np\u001b[39m.\u001b[39marray(pred) \u001b[39m>\u001b[39m \u001b[39m0.5\u001b[39m)\u001b[39m.\u001b[39mreshape(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)))\n\u001b[1;32m     77\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mf1_scores\u001b[39m.\u001b[39mappend(\n\u001b[1;32m     78\u001b[0m     f1_score(np\u001b[39m.\u001b[39marray(gt)\u001b[39m.\u001b[39mreshape(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m), (np\u001b[39m.\u001b[39marray(pred) \u001b[39m>\u001b[39m \u001b[39m0.5\u001b[39m)\u001b[39m.\u001b[39mreshape(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)))\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/pytorch/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1954\u001b[0m, in \u001b[0;36mprecision_score\u001b[0;34m(y_true, y_pred, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   1825\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mprecision_score\u001b[39m(\n\u001b[1;32m   1826\u001b[0m     y_true,\n\u001b[1;32m   1827\u001b[0m     y_pred,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1833\u001b[0m     zero_division\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mwarn\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   1834\u001b[0m ):\n\u001b[1;32m   1835\u001b[0m     \u001b[39m\"\"\"Compute the precision.\u001b[39;00m\n\u001b[1;32m   1836\u001b[0m \n\u001b[1;32m   1837\u001b[0m \u001b[39m    The precision is the ratio ``tp / (tp + fp)`` where ``tp`` is the number of\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1952\u001b[0m \u001b[39m    array([0.5, 1. , 1. ])\u001b[39;00m\n\u001b[1;32m   1953\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1954\u001b[0m     p, _, _, _ \u001b[39m=\u001b[39m precision_recall_fscore_support(\n\u001b[1;32m   1955\u001b[0m         y_true,\n\u001b[1;32m   1956\u001b[0m         y_pred,\n\u001b[1;32m   1957\u001b[0m         labels\u001b[39m=\u001b[39;49mlabels,\n\u001b[1;32m   1958\u001b[0m         pos_label\u001b[39m=\u001b[39;49mpos_label,\n\u001b[1;32m   1959\u001b[0m         average\u001b[39m=\u001b[39;49maverage,\n\u001b[1;32m   1960\u001b[0m         warn_for\u001b[39m=\u001b[39;49m(\u001b[39m\"\u001b[39;49m\u001b[39mprecision\u001b[39;49m\u001b[39m\"\u001b[39;49m,),\n\u001b[1;32m   1961\u001b[0m         sample_weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[1;32m   1962\u001b[0m         zero_division\u001b[39m=\u001b[39;49mzero_division,\n\u001b[1;32m   1963\u001b[0m     )\n\u001b[1;32m   1964\u001b[0m     \u001b[39mreturn\u001b[39;00m p\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/pytorch/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1573\u001b[0m, in \u001b[0;36mprecision_recall_fscore_support\u001b[0;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   1571\u001b[0m \u001b[39mif\u001b[39;00m beta \u001b[39m<\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m   1572\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mbeta should be >=0 in the F-beta score\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m-> 1573\u001b[0m labels \u001b[39m=\u001b[39m _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n\u001b[1;32m   1575\u001b[0m \u001b[39m# Calculate tp_sum, pred_sum, true_sum ###\u001b[39;00m\n\u001b[1;32m   1576\u001b[0m samplewise \u001b[39m=\u001b[39m average \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39msamples\u001b[39m\u001b[39m\"\u001b[39m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/pytorch/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1391\u001b[0m, in \u001b[0;36m_check_set_wise_labels\u001b[0;34m(y_true, y_pred, average, labels, pos_label)\u001b[0m\n\u001b[1;32m   1389\u001b[0m         \u001b[39mif\u001b[39;00m y_type \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mmulticlass\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m   1390\u001b[0m             average_options\u001b[39m.\u001b[39mremove(\u001b[39m\"\u001b[39m\u001b[39msamples\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m-> 1391\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   1392\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mTarget is \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m but average=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mbinary\u001b[39m\u001b[39m'\u001b[39m\u001b[39m. Please \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1393\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mchoose another average setting, one of \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m (y_type, average_options)\n\u001b[1;32m   1394\u001b[0m         )\n\u001b[1;32m   1395\u001b[0m \u001b[39melif\u001b[39;00m pos_label \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m (\u001b[39mNone\u001b[39;00m, \u001b[39m1\u001b[39m):\n\u001b[1;32m   1396\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m   1397\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mNote that pos_label (set to \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m) is ignored when \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1398\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39maverage != \u001b[39m\u001b[39m'\u001b[39m\u001b[39mbinary\u001b[39m\u001b[39m'\u001b[39m\u001b[39m (got \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m). You may use \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1401\u001b[0m         \u001b[39mUserWarning\u001b[39;00m,\n\u001b[1;32m   1402\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted']."
     ]
    }
   ],
   "source": [
    "# we have to mention that in order to provide objective evaluation, we compromise the dataset size, which also nagatively afftect the performance and generlaization.\n",
    "for setup in all_model_setups:\n",
    "    assert (\n",
    "        len(setup.sources) > 0 and len(setup.tasks) > 0\n",
    "    ), \"Need at least one source and task.\"\n",
    "\n",
    "    print_f.print_title(\"Preparing for the training.\")\n",
    "\n",
    "    train_info = TrainingInfo(setup)\n",
    "\n",
    "    model = create_model_from_setup(setup=setup)\n",
    "    model = model.to(device)\n",
    "\n",
    "    train_info.all_tasks = list(model.task_performers.keys())\n",
    "    print(f\" Model Size [{get_model_size_in_MB(model):.3f}] MB\")\n",
    "\n",
    "    ################ Datasets ################\n",
    "    dataset_params_dict = {\n",
    "        \"MIMIC_EYE_PATH\": MIMIC_EYE_PATH,\n",
    "        \"labels_cols\": setup.lesion_label_cols,\n",
    "        \"with_clincal\": SourceStrs.CLINICAL in setup.sources,\n",
    "        \"with_xrays\": SourceStrs.XRAYS in setup.sources,\n",
    "        \"with_bboxes\": TaskStrs.LESION_DETECTION in setup.tasks,\n",
    "        \"with_fixations\": TaskStrs.FIXATION_GENERATION in setup.tasks,\n",
    "        \"with_chexpert\": TaskStrs.CHEXPERT_CLASSIFICATION in setup.tasks,\n",
    "        \"with_negbio\": TaskStrs.NEGBIO_CLASSIFICATION in setup.tasks,\n",
    "        \"fiaxtions_mode\": setup.fiaxtions_mode,\n",
    "        \"clinical_numerical_cols\": setup.clinical_num,\n",
    "        \"clinical_categorical_cols\": setup.clinical_cat,\n",
    "    }\n",
    "\n",
    "    detect_eval_dataset, train_dataset, val_dataset, test_dataset = get_datasets(\n",
    "        dataset_params_dict=dataset_params_dict,\n",
    "    )\n",
    "\n",
    "    train_dataloader, val_dataloader, test_dataloader = get_dataloaders(\n",
    "        train_dataset, val_dataset, test_dataset, batch_size=setup.batch_size,\n",
    "    )\n",
    "\n",
    "    train_coco = None\n",
    "    val_coco = None\n",
    "    test_coco = None\n",
    "    eval_params_dict = None\n",
    "\n",
    "    if TaskStrs.LESION_DETECTION in setup.tasks:\n",
    "        train_coco, val_coco, test_coco, eval_params_dict = get_coco_eval_params(\n",
    "            source_name=SourceStrs.XRAYS,\n",
    "            task_name=TaskStrs.LESION_DETECTION,\n",
    "            train_dataloader=train_dataloader,\n",
    "            val_dataloader=val_dataloader,\n",
    "            test_dataloader=test_dataloader,\n",
    "            detect_eval_dataset=detect_eval_dataset,\n",
    "            iou_thrs=setup.iou_thrs,\n",
    "            use_iobb=setup.use_iobb,\n",
    "        )\n",
    "\n",
    "    train_info.timer.start_training()\n",
    "\n",
    "    dynamic_loss_weight = get_dynamic_loss(\n",
    "        loss_keys=model.get_all_losses_keys(), device=device\n",
    "    )\n",
    "    params = model.get_all_params(dynamic_loss_weight=dynamic_loss_weight)\n",
    "\n",
    "    iou_types = get_iou_types(model, setup)\n",
    "    optimizer = get_optimiser(params, setup)\n",
    "    lr_scheduler = get_lr_scheduler(optimizer, setup)\n",
    "\n",
    "    print_f.print_title(\n",
    "        f\"Start training. Preparing Took [{train_info.timer.has_took_sec_from_init()}] sec\"\n",
    "    )\n",
    "\n",
    "    train_info.timer.start_training()\n",
    "\n",
    "    val_loss = None\n",
    "\n",
    "    # Start the training from here.\n",
    "    for e in range(1, num_epochs + 1):\n",
    "\n",
    "        print_f.print_title(f\"Training model: [{setup.name}]\")\n",
    "\n",
    "        print(train_info)\n",
    "\n",
    "        train_info.epoch = e\n",
    "\n",
    "        train_info.timer.start_epoch()\n",
    "\n",
    "        if (\n",
    "            any(\n",
    "                [\n",
    "                    isinstance(p, ObjectDetectionPerformer)\n",
    "                    for p in model.task_performers.values()\n",
    "                ]\n",
    "            )\n",
    "            and train_info.epoch > setup.gt_in_train_till\n",
    "        ):\n",
    "            model.task_performers[\n",
    "                TaskStrs.LESION_DETECTION\n",
    "            ].roi_heads.use_gt_in_train = False\n",
    "\n",
    "        ###### Perform training and show the training result here ######\n",
    "        model.train()\n",
    "\n",
    "        train_info.last_train_evaluator, train_loger = train_one_epoch(\n",
    "            setup=setup,\n",
    "            model=model,\n",
    "            optimizer=optimizer,\n",
    "            # data_loader=train_dataloader,\n",
    "            data_loader=test_dataloader,\n",
    "            device=device,\n",
    "            epoch=train_info.epoch,\n",
    "            print_freq=10,\n",
    "            iou_types=iou_types,\n",
    "            coco=train_coco,\n",
    "            score_thres=None,\n",
    "            evaluate_on_run=True,\n",
    "            params_dict=eval_params_dict,\n",
    "            dynamic_loss_weight=dynamic_loss_weight,\n",
    "        )\n",
    "\n",
    "        # train_info.train_evaluators.append(train_evaluator)\n",
    "        train_info.train_losses.append(get_data_from_metric_logger(train_loger))\n",
    "        ################################################################\n",
    "\n",
    "        ####### Put the model into evaluation mode, start evaluating the current model #######\n",
    "        model.eval()\n",
    "\n",
    "        train_info.last_val_evaluator, val_logger = evaluate(\n",
    "            setup=setup,\n",
    "            model=model,\n",
    "            data_loader=val_dataloader,\n",
    "            device=device,\n",
    "            params_dict=eval_params_dict,\n",
    "            coco=val_coco,\n",
    "            iou_types=iou_types,\n",
    "            score_thres=None,\n",
    "        )\n",
    "\n",
    "        # train_info.val_evaluators.append(val_evaluator)\n",
    "        train_info.val_losses.append(get_data_from_metric_logger(val_logger))\n",
    "\n",
    "        train_info.performance[\"train\"].append(\n",
    "            get_performance(\n",
    "                train_info.all_tasks,\n",
    "                train_info.last_train_evaluator,\n",
    "                iouThr=0.5,\n",
    "                areaRng=\"all\",\n",
    "                maxDets=10,\n",
    "            )\n",
    "        )\n",
    "\n",
    "        train_info.performance[\"val\"].append(\n",
    "            get_performance(\n",
    "                train_info.all_tasks,\n",
    "                train_info.last_val_evaluator,\n",
    "                iouThr=0.5,\n",
    "                areaRng=\"all\",\n",
    "                maxDets=10,\n",
    "            )\n",
    "        )\n",
    "\n",
    "        if setup.measure_test:\n",
    "            train_info.test_evaluator, test_logger = evaluate(\n",
    "                setup=setup,\n",
    "                model=model,\n",
    "                data_loader=test_dataloader,\n",
    "                device=device,\n",
    "                params_dict=eval_params_dict,\n",
    "                coco=test_coco,\n",
    "                iou_types=iou_types,\n",
    "                score_thres=None,\n",
    "            )\n",
    "            train_info.test_losses.append(get_data_from_metric_logger(test_logger))\n",
    "\n",
    "            train_info.performance[\"test\"].append(\n",
    "                get_performance(\n",
    "                    train_info.all_tasks,\n",
    "                    train_info.test_evaluator,\n",
    "                    iouThr=0.5,\n",
    "                    areaRng=\"all\",\n",
    "                    maxDets=10,\n",
    "                )\n",
    "            )\n",
    "\n",
    "        # update the learning rate\n",
    "\n",
    "        val_loss = train_info.val_losses[-1][\"loss\"]\n",
    "\n",
    "        epoch_took, sec_already_took, speed = train_info.timer.end_epoch(\n",
    "            train_info.epoch\n",
    "        )\n",
    "\n",
    "        if train_info.epoch > setup.warmup_epochs:\n",
    "            if not lr_scheduler is None:\n",
    "                if isinstance(lr_scheduler, optim.lr_scheduler.ReduceLROnPlateau):\n",
    "                    if (\n",
    "                        setup.reduceLROnPlateau_full_stop\n",
    "                        and lr_scheduler.num_bad_epochs\n",
    "                        >= setup.reduceLROnPlateau_patience\n",
    "                    ):\n",
    "                        print_f.print_title(\n",
    "                            f\"| EarlyStop | Epoch [{train_info.epoch}] Done | It has took [{sec_already_took/60:.2f}] min, Avg time: [{speed:.2f}] sec/epoch | Estimate time for [{num_epochs}] epochs: [{speed*num_epochs/60:.2f}] min | Epoch took [{epoch_took.seconds}] sec |\"\n",
    "                        )\n",
    "                        break\n",
    "                    lr_scheduler.step(val_loss)\n",
    "                else:\n",
    "                    lr_scheduler.step()\n",
    "\n",
    "        # Clean everything before we show the evaluating result in this stage, so we can inspect the training progress.\n",
    "        clear_output()\n",
    "\n",
    "        # if model_setup.record_training_performance:\n",
    "        # plot all matrics\n",
    "        plot_performance(\n",
    "            performance=train_info.performance,\n",
    "            all_tasks=train_info.all_tasks,\n",
    "            fig_title=\"Performance\",\n",
    "        )\n",
    "\n",
    "        plot_losses(\n",
    "            train_info.train_losses,\n",
    "            train_info.val_losses,\n",
    "            test_logers=train_info.test_losses,\n",
    "        )\n",
    "\n",
    "        print_str = f\"| Epoch [{train_info.epoch}] Done | It has took [{sec_already_took/60:.2f}] min, Avg time: [{speed:.2f}] sec/epoch | Estimate time for [{num_epochs}] epochs: [{speed*num_epochs/60:.2f}] min | Epoch took [{epoch_took.seconds}] sec | \"\n",
    "\n",
    "        if lr_scheduler and hasattr(lr_scheduler, \"num_bad_epochs\"):\n",
    "            print_str += f\"Patience [{lr_scheduler.num_bad_epochs}] |\"\n",
    "\n",
    "        print_f.print_title(print_str)\n",
    "\n",
    "        train_info\n",
    "\n",
    "        #######################################################################################\n",
    "        if setup.save_early_stop_model:\n",
    "            val_performance_value, train_info = check_best(\n",
    "                setup=setup,\n",
    "                val_performance_value=train_info.performance[\"val\"][-1][\n",
    "                    setup.performance_standard_task\n",
    "                ][setup.performance_standard_metric],\n",
    "                device=device,\n",
    "                eval_params_dict=eval_params_dict,\n",
    "                train_info=train_info,\n",
    "                model=model,\n",
    "                optim=optimizer,\n",
    "                test_dataloader=test_dataloader,\n",
    "                test_coco=test_coco,\n",
    "                iou_types=iou_types,\n",
    "                score_thres=None,\n",
    "                dynamic_weight=dynamic_loss_weight,\n",
    "            )\n",
    "\n",
    "    train_info = end_train(\n",
    "        setup=setup,\n",
    "        train_info=train_info,\n",
    "        model=model,\n",
    "        optim=optimizer,\n",
    "        eval_params_dict=eval_params_dict,\n",
    "        last_val_performance=train_info.performance[\"val\"][-1][\n",
    "            setup.performance_standard_task\n",
    "        ][setup.performance_standard_metric],\n",
    "        test_dataloader=test_dataloader,\n",
    "        device=device,\n",
    "        test_coco=test_coco,\n",
    "        iou_types=iou_types,\n",
    "        score_thres=None,\n",
    "        dynamic_weight=dynamic_loss_weight,\n",
    "    )\n",
    "\n",
    "    train_infos.append(train_info)\n",
    "\n",
    "\n",
    "# TODO: allow for any kind of pipeline.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.00067901611328125,\n",
       " 0.0033111572265625,\n",
       " 0.000255584716796875,\n",
       " 0.00171661376953125,\n",
       " 0.0,\n",
       " 0.005031585693359375,\n",
       " 0.0067138671875,\n",
       " 0.0,\n",
       " 0.000133514404296875,\n",
       " 3.4332275390625e-05,\n",
       " 0.000637054443359375,\n",
       " 0.0015411376953125,\n",
       " 0.0,\n",
       " 0.00139617919921875,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.00043487548828125,\n",
       " 0.000682830810546875,\n",
       " 0.000141143798828125,\n",
       " 0.00478363037109375,\n",
       " 0.0,\n",
       " 0.005218505859375,\n",
       " 0.003734588623046875,\n",
       " 0.0,\n",
       " 0.000354766845703125,\n",
       " 0.0,\n",
       " 0.00022125244140625,\n",
       " 0.0,\n",
       " 0.00397491455078125,\n",
       " 0.000225067138671875,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.004596710205078125,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.00074005126953125,\n",
       " 0.004131317138671875,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.001247406005859375,\n",
       " 0.00201416015625,\n",
       " 0.002574920654296875,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.000591278076171875,\n",
       " 0.000179290771484375,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.00058746337890625,\n",
       " 0.000453948974609375,\n",
       " 0.0013275146484375,\n",
       " 0.0,\n",
       " 0.001773834228515625,\n",
       " 0.000652313232421875,\n",
       " 0.00023651123046875,\n",
       " 0.00029754638671875,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.00571441650390625,\n",
       " 0.003795623779296875,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0024871826171875,\n",
       " 0.001873016357421875,\n",
       " 0.005657196044921875,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.000186920166015625,\n",
       " 0.000553131103515625,\n",
       " 0.0,\n",
       " 8.0108642578125e-05,\n",
       " 2.6702880859375e-05,\n",
       " 4.1961669921875e-05,\n",
       " 0.0011749267578125,\n",
       " 0.0028839111328125,\n",
       " 0.0,\n",
       " 0.000308990478515625,\n",
       " 0.001445770263671875,\n",
       " 0.0,\n",
       " 0.001201629638671875,\n",
       " 0.0,\n",
       " 0.000423431396484375,\n",
       " 5.340576171875e-05,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.002536773681640625,\n",
       " 0.0,\n",
       " 0.004138946533203125,\n",
       " 0.002117156982421875,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.00702667236328125,\n",
       " 0.004230499267578125,\n",
       " 0.000690460205078125,\n",
       " 0.0,\n",
       " 0.003711700439453125,\n",
       " 0.00078582763671875,\n",
       " 0.00336456298828125,\n",
       " 0.0,\n",
       " 0.00060272216796875,\n",
       " 0.0002593994140625,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.001346588134765625,\n",
       " 0.0,\n",
       " 0.000396728515625,\n",
       " 8.392333984375e-05,\n",
       " 0.0,\n",
       " 0.000396728515625,\n",
       " 0.001926422119140625,\n",
       " 0.00464630126953125,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.00302886962890625,\n",
       " 0.00026702880859375,\n",
       " 0.001850128173828125,\n",
       " 0.003604888916015625,\n",
       " 0.0028839111328125,\n",
       " 0.0001373291015625,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.000896453857421875,\n",
       " 0.004573822021484375,\n",
       " 6.103515625e-05,\n",
       " 9.5367431640625e-05,\n",
       " 0.000385284423828125,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.00421905517578125,\n",
       " 0.000247955322265625,\n",
       " 0.0,\n",
       " 0.00096893310546875,\n",
       " 0.0,\n",
       " 0.003864288330078125,\n",
       " 0.0001220703125,\n",
       " 0.00086212158203125,\n",
       " 0.0005950927734375,\n",
       " 0.00334930419921875,\n",
       " 0.0,\n",
       " 0.007274627685546875,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.00032806396484375,\n",
       " 0.00104522705078125,\n",
       " 3.4332275390625e-05,\n",
       " 0.0001373291015625,\n",
       " 0.00063323974609375,\n",
       " 8.392333984375e-05,\n",
       " 0.000804901123046875,\n",
       " 0.001190185546875,\n",
       " 0.00041961669921875,\n",
       " 0.0,\n",
       " 6.866455078125e-05,\n",
       " 0.00152587890625,\n",
       " 0.003871917724609375,\n",
       " 0.00550079345703125,\n",
       " 0.0001068115234375,\n",
       " 0.0,\n",
       " 0.00074005126953125,\n",
       " 0.00849151611328125,\n",
       " 0.00466156005859375,\n",
       " 0.003078460693359375,\n",
       " 0.00087738037109375,\n",
       " 0.002674102783203125,\n",
       " 0.000885009765625,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.00060272216796875,\n",
       " 0.0,\n",
       " 3.4332275390625e-05,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.001338958740234375,\n",
       " 0.00240325927734375,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 6.103515625e-05,\n",
       " 0.0,\n",
       " 0.00208282470703125,\n",
       " 0.001018524169921875,\n",
       " 0.0,\n",
       " 0.005706787109375,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.00017547607421875,\n",
       " 0.0,\n",
       " 3.814697265625e-06,\n",
       " 0.000743865966796875,\n",
       " 0.00067138671875,\n",
       " 0.0052947998046875,\n",
       " 0.0,\n",
       " 0.000530242919921875,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.00090789794921875,\n",
       " 0.00018310546875,\n",
       " 0.0,\n",
       " 6.866455078125e-05,\n",
       " 0.00495147705078125,\n",
       " 0.003040313720703125,\n",
       " 0.001697540283203125,\n",
       " 0.00081634521484375,\n",
       " 0.0,\n",
       " 0.000537872314453125,\n",
       " 0.0,\n",
       " 0.00016021728515625,\n",
       " 0.0020294189453125,\n",
       " 0.001873016357421875,\n",
       " 0.001857757568359375,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.1444091796875e-05,\n",
       " 0.004482269287109375,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.002063751220703125,\n",
       " 0.003284454345703125,\n",
       " 0.0003509521484375,\n",
       " 0.002849578857421875,\n",
       " 0.00205230712890625,\n",
       " 0.00362396240234375,\n",
       " 0.0,\n",
       " 0.000186920166015625,\n",
       " 0.0,\n",
       " 0.001743316650390625,\n",
       " 0.003566741943359375,\n",
       " 0.0007171630859375,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.00022125244140625,\n",
       " 0.002452850341796875,\n",
       " 0.00058746337890625,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 8.392333984375e-05,\n",
       " 0.0,\n",
       " 0.000335693359375,\n",
       " 0.0,\n",
       " 0.000213623046875,\n",
       " 0.009777069091796875,\n",
       " 0.00118255615234375,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.000690460205078125,\n",
       " 0.001605987548828125,\n",
       " 0.000255584716796875,\n",
       " 0.00043487548828125,\n",
       " 0.000736236572265625,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.00019073486328125,\n",
       " 0.000152587890625,\n",
       " 0.0,\n",
       " 0.0006103515625,\n",
       " 3.4332275390625e-05,\n",
       " 6.103515625e-05,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.000843048095703125,\n",
       " 0.005268096923828125,\n",
       " 0.0,\n",
       " 0.000438690185546875,\n",
       " 0.002460479736328125,\n",
       " 0.000400543212890625,\n",
       " 0.0,\n",
       " 0.0005645751953125,\n",
       " 0.0,\n",
       " 0.00353240966796875,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.001583099365234375,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.008392333984375,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.001361846923828125,\n",
       " 0.0,\n",
       " 0.0004119873046875,\n",
       " 0.001804351806640625,\n",
       " 0.00048828125,\n",
       " 0.0,\n",
       " 0.013439178466796875,\n",
       " 0.000415802001953125,\n",
       " 0.000286102294921875,\n",
       " 0.002895355224609375,\n",
       " 0.00045013427734375,\n",
       " 0.0,\n",
       " 0.0052337646484375,\n",
       " 0.0,\n",
       " 0.00035858154296875,\n",
       " 0.002288818359375,\n",
       " 0.005558013916015625,\n",
       " 0.001556396484375,\n",
       " 0.00061798095703125,\n",
       " 3.814697265625e-05,\n",
       " 0.00022125244140625,\n",
       " 0.0,\n",
       " 0.003509521484375,\n",
       " 0.002414703369140625,\n",
       " 0.0,\n",
       " 0.0027008056640625,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0025482177734375,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.001415252685546875,\n",
       " 0.000316619873046875,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0003662109375,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.00012969970703125,\n",
       " 0.00026702880859375,\n",
       " 0.004055023193359375,\n",
       " 0.001216888427734375,\n",
       " 0.000278472900390625,\n",
       " 0.000911712646484375,\n",
       " 0.0,\n",
       " 0.004795074462890625,\n",
       " 0.00016021728515625,\n",
       " 0.0003509521484375,\n",
       " 0.00061798095703125,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.00524139404296875,\n",
       " 0.003787994384765625,\n",
       " 4.1961669921875e-05,\n",
       " 0.0009002685546875,\n",
       " 0.007709503173828125,\n",
       " 0.012599945068359375,\n",
       " 0.0,\n",
       " 0.001895904541015625,\n",
       " 0.000888824462890625,\n",
       " 6.103515625e-05,\n",
       " 0.0,\n",
       " 0.002288818359375,\n",
       " 0.00022125244140625,\n",
       " 0.0,\n",
       " 0.00695037841796875,\n",
       " 0.001384735107421875,\n",
       " 0.003448486328125,\n",
       " 0.002197265625,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.00054931640625,\n",
       " 0.000202178955078125,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.000827789306640625,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.000118255615234375,\n",
       " 0.000225067138671875,\n",
       " 0.0,\n",
       " 0.000125885009765625,\n",
       " 0.002849578857421875,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.00215911865234375,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.005084991455078125,\n",
       " 0.0,\n",
       " 0.00121307373046875,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 4.57763671875e-05,\n",
       " 5.7220458984375e-05,\n",
       " 0.00029754638671875,\n",
       " 0.0,\n",
       " 0.001293182373046875,\n",
       " 0.0,\n",
       " 0.000171661376953125,\n",
       " 0.0,\n",
       " 0.0046539306640625,\n",
       " 0.00016021728515625,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.002292633056640625,\n",
       " 0.001087188720703125,\n",
       " 0.0,\n",
       " 0.00025177001953125,\n",
       " 0.0003204345703125,\n",
       " 0.0,\n",
       " 0.00226593017578125,\n",
       " 0.0,\n",
       " 0.000926971435546875,\n",
       " 0.001739501953125,\n",
       " 0.0003814697265625,\n",
       " 0.000583648681640625,\n",
       " 0.0005340576171875,\n",
       " 0.001251220703125,\n",
       " 0.0,\n",
       " 0.000518798828125,\n",
       " 0.000286102294921875,\n",
       " 0.000125885009765625,\n",
       " 0.0,\n",
       " 0.0013427734375,\n",
       " 0.001171112060546875,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0014190673828125,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.000308990478515625,\n",
       " 0.0,\n",
       " 0.0003509521484375,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.004062652587890625,\n",
       " 0.000148773193359375,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 2.6702880859375e-05,\n",
       " 0.0]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_info.last_train_evaluator['fixation-generation'].ious"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_iou(preds, gts):\n",
    "    intersection = np.logical_and(gts, preds)\n",
    "    union = np.logical_or(gts, preds)\n",
    "    iou_score = np.sum(intersection) / np.sum(union)\n",
    "    return iou_score \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_iou(train_info.last_train_evaluator['fixation-generation'].gts[0], train_info.last_train_evaluator['fixation-generation'].preds[0])\n",
    "\n",
    "# did I put the relu at the last layer for the decovder part? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('uint8')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_info.last_train_evaluator['fixation-generation'].gts[0].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float32')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_info.last_train_evaluator['fixation-generation'].preds[0].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_infos' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_21292/530910633.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mtrain_info\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtrain_infos\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_info\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     plot_performance(\n\u001b[0;32m      4\u001b[0m         \u001b[0mperformance\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain_info\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mperformance\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[0mall_tasks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain_info\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mall_tasks\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_infos' is not defined"
     ]
    }
   ],
   "source": [
    "for train_info in train_infos:\n",
    "    print(train_info)\n",
    "    plot_performance(\n",
    "        performance=train_info.performance,\n",
    "        all_tasks=train_info.all_tasks,\n",
    "        fig_title=\"Performance\",\n",
    "    )\n",
    "\n",
    "    plot_losses(\n",
    "        train_info.train_losses,\n",
    "        train_info.val_losses,\n",
    "        test_logers=train_info.test_losses,\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "52a48fdedee40b77eb251917c5aa239bf02f1ab8c93cc13fe7347f570eadc6b9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
