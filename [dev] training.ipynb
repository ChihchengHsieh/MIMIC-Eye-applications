{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import utils.print as print_f\n",
    "\n",
    "from utils.engine import evaluate, get_iou_types\n",
    "from utils.plot import plot_losses, plot_ap_ars\n",
    "\n",
    "from models.setup import ModelSetup\n",
    "from models.build import create_multimodal_rcnn_model\n",
    "from models.train import TrainingInfo\n",
    "from utils.save import check_best, end_train, get_data_from_metric_logger\n",
    "from data.load import get_datasets, get_dataloaders\n",
    "from IPython.display import clear_output\n",
    "from utils.eval import get_ap_ar, get_ap_ar_for_train_val\n",
    "from utils.train import get_optimiser, get_lr_scheduler, print_params_setup, get_coco_eval_params, get_dynamic_loss, get_params\n",
    "from utils.init import reproducibility, clean_memory_get_device\n",
    "from data.constants import DEFAULT_REFLACX_LABEL_COLS\n",
    "from data.paths import MIMIC_EYE_PATH\n",
    "from datetime import datetime\n",
    "from utils.coco_utils import get_cocos\n",
    "from utils.coco_eval import get_eval_params_dict\n",
    "from models.dynamic_loss import DynamicWeightedLoss\n",
    "from utils.engine import train_one_epoch, evaluate\n",
    "from torch import optim\n",
    "\n",
    "\n",
    "## Suppress the assignement warning from pandas.r\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "\n",
    "## Supress user warning\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_iobb = True\n",
    "io_type_str = \"IoBB\" if use_iobb else \"IoU\"\n",
    "labels_cols = DEFAULT_REFLACX_LABEL_COLS\n",
    "iou_thrs = np.array([0.5])\n",
    "\n",
    "common_args = {\n",
    "    # \"use_custom_model\": True,\n",
    "    # \"use_early_stop_model\": True,\n",
    "    \"optimiser\": \"sgd\",\n",
    "    \"lr\": 1e-3,\n",
    "    \"weight_decay\": 1e-5,\n",
    "    # \"pretrained\": True,\n",
    "    \"record_training_performance\": True,\n",
    "    # \"dataset_mode\": \"normal\",\n",
    "    \"image_size\": 512,\n",
    "    \"batch_size\": 4,\n",
    "    \"warmup_epochs\": 0,\n",
    "    \"lr_scheduler\": \"ReduceLROnPlateau\",\n",
    "    \"reduceLROnPlateau_factor\": 0.1,\n",
    "    \"reduceLROnPlateau_patience\": 999,\n",
    "    \"reduceLROnPlateau_full_stop\": True,\n",
    "    \"multiStepLR_milestones\": 100,\n",
    "    \"multiStepLR_gamma\": 0.1,\n",
    "    \"use_mask\": True,\n",
    "    # \"clinical_num_len\": len(DEFAULT_MIMIC_CLINICAL_NUM_COLS),\n",
    "    \"gt_in_train_till\": 999,\n",
    "    \"box_head_dropout_rate\": 0,\n",
    "    # \"spatialise_method\": \"convs\",  # [convs, repeat]\n",
    "    # \"normalise_clinical_num\": False,\n",
    "    \"measure_test\": True,\n",
    "}\n",
    "\n",
    "fusion_add_args = {\n",
    "    \"fuse_depth\": 0,\n",
    "    \"fusion_residule\": False,\n",
    "    \"fusion_strategy\": \"add\",\n",
    "}\n",
    "\n",
    "fusion_concat_args = {\n",
    "    \"fuse_depth\": 1,\n",
    "    \"fusion_residule\": False,\n",
    "    \"fusion_strategy\": \"concat\",\n",
    "}\n",
    "\n",
    "small_model_args = {\n",
    "    \"mask_hidden_layers\": 64,\n",
    "    \"fuse_conv_channels\": 64,\n",
    "    # \"clinical_input_channels\": 64,\n",
    "    \"representation_size\": 64,  # 32\n",
    "    # \"clinical_conv_channels\": 64,\n",
    "    # \"clinical_expand_conv_channels\": 64,\n",
    "    \"backbone_out_channels\": 64,\n",
    "}\n",
    "\n",
    "large_model_args = {\n",
    "    \"mask_hidden_layers\": 256,\n",
    "    \"fuse_conv_channels\": 256,\n",
    "    \"clinical_input_channels\": 256,\n",
    "    \"representation_size\": 256,  # 32\n",
    "    \"clinical_conv_channels\": 256,\n",
    "    \"clinical_expand_conv_channels\": 256,\n",
    "    \"backbone_out_channels\": 256,\n",
    "}\n",
    "\n",
    "mobilenet_args = {\n",
    "    \"backbone\": \"mobilenet_v3\",\n",
    "    \"using_fpn\": False,\n",
    "}\n",
    "\n",
    "resnet_args = {\n",
    "    \"using_fpn\": True,\n",
    "    \"backbone\": \"resnet50\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This notebook will running on device: [CPU]\n"
     ]
    }
   ],
   "source": [
    "device = clean_memory_get_device()\n",
    "reproducibility()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.transforms import get_tensorise_h_flip_transform\n",
    "from data.constants import DEFAULT_REFLACX_LABEL_COLS\n",
    "from data.paths import MIMIC_EYE_PATH\n",
    "from data.datasets import ReflacxObjectDetectionDataset\n",
    "from torch.utils.data import DataLoader\n",
    "from data.datasets import collate_fn\n",
    "from data.load import seed_worker, get_dataloader_g\n",
    "\n",
    "dataset_params_dict = {\n",
    "    \"MIMIC_EYE_PATH\": MIMIC_EYE_PATH,\n",
    "    # \"with_clinical\": model_setup.use_clinical,\n",
    "    \"bbox_to_mask\": True,\n",
    "    \"labels_cols\": DEFAULT_REFLACX_LABEL_COLS,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.components.feature_extractors import ImageFeatureExtractor\n",
    "from models.components.fusors import NoActionFusor\n",
    "from models.components.task_performers import ObjectDetectionWithMaskParameters, ObjectDetectionWithMaskPerformer\n",
    "from models.frameworks import ExtractFusePerform\n",
    "from models.backbones import get_normal_backbone\n",
    "from models.setup import ModelSetup\n",
    "from data.constants import DEFAULT_REFLACX_LABEL_COLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_model_setups = [\n",
    "    ModelSetup(\n",
    "        name=\"baseline\",\n",
    "        # use_clinical=True,\n",
    "            # spatialise_clinical=True,\n",
    "            # add_clinical_to_roi_heads=True,\n",
    "        **mobilenet_args,\n",
    "        **small_model_args,\n",
    "        **common_args,\n",
    "        # **fusion_add_args,\n",
    "        # including_clinical_num =  [\n",
    "        #         \"age\",\n",
    "        #         # \"temperature\",\n",
    "        #         # \"heartrate\",\n",
    "        #         \"resprate\",\n",
    "        #         # \"o2sat\",\n",
    "        #         # \"sbp\",\n",
    "        #         # \"dbp\",\n",
    "        #         # \"pain\",\n",
    "        #         # \"acuity\",\n",
    "        #     ],\n",
    "        #     including_clinical_cat = [\n",
    "        #         \"gender\"\n",
    "        #     ],\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 1\n",
    "train_infos = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================Preparing for the training.====================\n",
      "Using pretrained backbone. mobilenet_v3\n",
      "[model]: 0\n",
      "Using SGD as optimizer with lr=0.001\n",
      "====================Start training. Preparing Took [0] sec====================\n",
      "====================Training model: [baseline]====================\n",
      "========================================For Training [baseline]========================================\n",
      "ModelSetup(name='baseline', use_heatmaps=False, with_fixations=False, with_pupil=False, with_1st_third_fixations=False, with_2nd_third_fixations=False, with_rad_silence=False, with_rad_speaking=False, save_early_stop_model=True, record_training_performance=True, backbone='mobilenet_v3', optimiser='sgd', lr=0.001, weight_decay=1e-05, image_backbone_pretrained=True, heatmap_backbone_pretrained=False, image_size=512, backbone_out_channels=64, batch_size=4, warmup_epochs=0, lr_scheduler='ReduceLROnPlateau', reduceLROnPlateau_factor=0.1, reduceLROnPlateau_patience=999, reduceLROnPlateau_full_stop=True, multiStepLR_milestones=100, multiStepLR_gamma=0.1, representation_size=64, mask_hidden_layers=64, using_fpn=False, use_mask=True, fuse_conv_channels=64, box_head_dropout_rate=0, fuse_depth=4, fusion_strategy='concat', fusion_residule=False, gt_in_train_till=999, measure_test=True, eval_freq=10)\n",
      "=======================================================================================================\n",
      "\n",
      "Best AP validation model has been saved to: [None]\n",
      "Best AR validation model has been saved to: [None]\n",
      "The final model has been saved to: [None]\n",
      "\n",
      "=======================================================================================================\n",
      "Epoch: [1]  [  0/114]  eta: 0:15:24  lr: 0.001000  loss: 3.2298 (3.2298)  object-detection_loss_classifier: 1.7467 (1.7467)  object-detection_loss_box_reg: 0.0323 (0.0323)  object-detection_loss_mask: 0.7520 (0.7520)  object-detection_loss_objectness: 0.6931 (0.6931)  object-detection_loss_rpn_box_reg: 0.0056 (0.0056)  time: 8.1128  data: 0.2864\n",
      "Epoch: [1]  [ 10/114]  eta: 0:15:26  lr: 0.001000  loss: 3.2298 (3.2444)  object-detection_loss_classifier: 1.7501 (1.7505)  object-detection_loss_box_reg: 0.0293 (0.0273)  object-detection_loss_mask: 0.7520 (0.7693)  object-detection_loss_objectness: 0.6931 (0.6932)  object-detection_loss_rpn_box_reg: 0.0040 (0.0042)  time: 8.9086  data: 0.2979\n"
     ]
    }
   ],
   "source": [
    "# we have to mention that in order to provide objective evaluation, we compromise the dataset size, which also nagatively afftect the performance and generlaization.\n",
    "\n",
    "for setup in all_model_setups:\n",
    "\n",
    "    print_f.print_title(\"Preparing for the training.\")\n",
    "\n",
    "    train_info = TrainingInfo(setup)\n",
    "\n",
    "    if setup.measure_test:\n",
    "        # initialise the test recording list.\n",
    "        train_info.test_ap_ars = []\n",
    "\n",
    "    backbone = get_normal_backbone(setup)\n",
    "    image_extractor = ImageFeatureExtractor(backbone)\n",
    "    fusor = NoActionFusor()\n",
    "    params = ObjectDetectionWithMaskParameters()\n",
    "    performer = ObjectDetectionWithMaskPerformer(\n",
    "        params,\n",
    "        image_extractor.backbone.out_channels,\n",
    "        len(DEFAULT_REFLACX_LABEL_COLS) + 1\n",
    "    )\n",
    "    model = ExtractFusePerform(\n",
    "        feature_extractors={\"image\": image_extractor},\n",
    "        fusor=fusor,\n",
    "        task_performers={\"object-detection\": performer},\n",
    "    )\n",
    "    model.to(device)\n",
    "\n",
    "    ################ Datasets ################\n",
    "    dataset_params_dict = {\n",
    "        \"MIMIC_EYE_PATH\": MIMIC_EYE_PATH,\n",
    "        # \"with_clinical\": model_setup.use_clinical,\n",
    "        \"bbox_to_mask\": True,\n",
    "        \"labels_cols\": DEFAULT_REFLACX_LABEL_COLS,\n",
    "    }\n",
    "    \n",
    "    detect_eval_dataset, train_dataset, val_dataset, test_dataset = get_datasets(\n",
    "        dataset_params_dict=dataset_params_dict,\n",
    "    )\n",
    "\n",
    "    train_dataloader, val_dataloader, test_dataloader = get_dataloaders(\n",
    "        train_dataset, val_dataset, test_dataset, batch_size=setup.batch_size,\n",
    "    )\n",
    "\n",
    "    train_coco = None\n",
    "    train_coco, val_coco, test_coco, eval_params_dict = get_coco_eval_params(\n",
    "        train_dataloader,\n",
    "        val_dataloader,\n",
    "        test_dataloader,\n",
    "        detect_eval_dataset,\n",
    "        iou_thrs,\n",
    "        use_iobb,\n",
    "    )\n",
    "\n",
    "    # train_coco, val_coco, test_coco = get_cocos(\n",
    "    #     train_dataloader, val_dataloader, test_dataloader\n",
    "    # )\n",
    "\n",
    "    # set the clinical data if clinical data is used.\n",
    "    # if setup.use_clinical:\n",
    "    #     # set for every dataset\n",
    "    #     train_dataloader.dataset.set_clinical_features_used(\n",
    "    #         setup.including_clinical_num, setup.including_clinical_cat)\n",
    "    #     val_dataloader.dataset.set_clinical_features_used(\n",
    "    #         setup.including_clinical_num, setup.including_clinical_cat)\n",
    "    #     test_dataloader.dataset.set_clinical_features_used(\n",
    "    #         setup.including_clinical_num, setup.including_clinical_cat)\n",
    "\n",
    "    # eval_params_dict = get_eval_params_dict(\n",
    "    #     detect_eval_dataset, iou_thrs=iou_thrs, use_iobb=use_iobb,\n",
    "    # )\n",
    "\n",
    "    # dynamic_loss_weight = None\n",
    "    loss_keys = [\n",
    "        \"object-detection_loss_box_reg\",\n",
    "        \"object-detection_loss_classifier\",\n",
    "        \"object-detection_loss_mask\",\n",
    "        \"object-detection_loss_objectness\",\n",
    "        \"object-detection_loss_rpn_box_reg\",\n",
    "    ]\n",
    "\n",
    "\n",
    "    dynamic_loss_weight = DynamicWeightedLoss(\n",
    "        keys=loss_keys + [\"loss_mask\"] if setup.use_mask else loss_keys\n",
    "    )\n",
    "    dynamic_loss_weight.to(device)\n",
    "    print_params_setup(model)\n",
    "\n",
    "    params = [p for p in model.parameters() if p.requires_grad]\n",
    "    if dynamic_loss_weight:\n",
    "        params += [p for p in dynamic_loss_weight.parameters()\n",
    "                   if p.requires_grad]\n",
    "\n",
    "    iou_types = get_iou_types(model, setup)\n",
    "    optimizer = get_optimiser(params, setup)\n",
    "    lr_scheduler = get_lr_scheduler(optimizer, setup)\n",
    "\n",
    "    current_time = datetime.now()\n",
    "\n",
    "    print_f.print_title(\n",
    "        f\"Start training. Preparing Took [{ (current_time - train_info.start_t).seconds}] sec\"\n",
    "    )\n",
    "\n",
    "    train_info.start_t = datetime.now()\n",
    "\n",
    "    val_loss = None\n",
    "\n",
    "    # Start the training from here.\n",
    "    for e in range(num_epochs):\n",
    "\n",
    "        print_f.print_title(f\"Training model: [{setup.name}]\")\n",
    "        print(train_info)\n",
    "\n",
    "        train_info.epoch = e + 1\n",
    "\n",
    "        if train_info.epoch > setup.gt_in_train_till:\n",
    "            model.roi_heads.use_gt_in_train = False\n",
    "\n",
    "        ###### Perform training and show the training result here ######\n",
    "        model.train()\n",
    "\n",
    "        train_info.last_train_evaluator, train_loger = train_one_epoch(\n",
    "            setup=setup,\n",
    "            model=model,\n",
    "            optimizer=optimizer,\n",
    "            # data_loader=train_dataloader,\n",
    "            data_loader=test_dataloader,\n",
    "            device=device,\n",
    "            epoch=train_info.epoch,\n",
    "            print_freq=10,\n",
    "            iou_types=iou_types,\n",
    "            coco=train_coco,\n",
    "            score_thres=None,\n",
    "            evaluate_on_run=True,\n",
    "            params_dict=eval_params_dict,\n",
    "            dynamic_loss_weight=dynamic_loss_weight,\n",
    "        )\n",
    "\n",
    "        # train_info.train_evaluators.append(train_evaluator)\n",
    "        train_info.train_losses.append(\n",
    "            get_data_from_metric_logger(train_loger))\n",
    "        ################################################################\n",
    "\n",
    "        ####### Put the model into evaluation mode, start evaluating the current model #######\n",
    "        model.eval()\n",
    "\n",
    "        train_info.last_val_evaluator, val_logger = evaluate(\n",
    "            setup=setup,\n",
    "            model=model,\n",
    "            data_loader=val_dataloader,\n",
    "            device=device,\n",
    "            params_dict=eval_params_dict,\n",
    "            coco=val_coco,\n",
    "            iou_types=iou_types,\n",
    "            score_thres=None,\n",
    "        )\n",
    "\n",
    "        # train_info.val_evaluators.append(val_evaluator)\n",
    "        train_info.val_losses.append(get_data_from_metric_logger(val_logger))\n",
    "\n",
    "        train_ap_ar, val_ap_ar = get_ap_ar_for_train_val(\n",
    "            train_info.last_train_evaluator,\n",
    "            train_info.last_val_evaluator,\n",
    "            areaRng=\"all\",\n",
    "            iouThr=0.5,\n",
    "            maxDets=10,\n",
    "        )\n",
    "\n",
    "        train_info.train_ap_ars.append(train_ap_ar)\n",
    "        train_info.val_ap_ars.append(val_ap_ar)\n",
    "\n",
    "        if setup.measure_test:\n",
    "            train_info.test_evaluator, test_logger = evaluate(\n",
    "                setup=setup,\n",
    "                model=model,\n",
    "                data_loader=test_dataloader,\n",
    "                device=device,\n",
    "                params_dict=eval_params_dict,\n",
    "                coco=test_coco,\n",
    "                iou_types=iou_types,\n",
    "                score_thres=None,\n",
    "            )\n",
    "            train_info.test_losses.append(\n",
    "                get_data_from_metric_logger(test_logger))\n",
    "            test_ap_ar = get_ap_ar(\n",
    "                train_info.test_evaluator, areaRng=\"all\", iouThr=0.5, maxDets=10,\n",
    "            )\n",
    "            train_info.test_ap_ars.append(test_ap_ar)\n",
    "\n",
    "        # update the learning rate\n",
    "\n",
    "        val_loss = train_info.val_losses[-1][\"loss\"]\n",
    "\n",
    "        if train_info.epoch > setup.warmup_epochs:\n",
    "            if not lr_scheduler is None:\n",
    "                if isinstance(lr_scheduler, optim.lr_scheduler.ReduceLROnPlateau):\n",
    "                    if (\n",
    "                        setup.reduceLROnPlateau_full_stop\n",
    "                        and lr_scheduler.num_bad_epochs\n",
    "                        >= setup.reduceLROnPlateau_patience\n",
    "                    ):\n",
    "                        print_f.print_title(\n",
    "                            f\"| EarlyStop | Epoch [{train_info.epoch}] Done | It has took [{sec_took/60:.2f}] min, Avg time: [{speed:.2f}] sec/epoch | Estimate time for [{num_epochs}] epochs: [{speed*num_epochs/60:.2f}] min | Epoch took [{epoch_took.seconds}] sec |\"\n",
    "                        )\n",
    "                        break\n",
    "                    lr_scheduler.step(val_loss)\n",
    "                else:\n",
    "                    lr_scheduler.step()\n",
    "\n",
    "        # Clean everything before we show the evaluating result in this stage, so we can inspect the training progress.\n",
    "        clear_output()\n",
    "\n",
    "        # if model_setup.record_training_performance:\n",
    "        plot_ap_ars(\n",
    "            train_ap_ars=train_info.train_ap_ars,\n",
    "            val_ap_ars=train_info.val_ap_ars,\n",
    "            test_ap_ars=train_info.test_ap_ars,\n",
    "        )\n",
    "\n",
    "        plot_losses(train_info.train_losses, train_info.val_losses,\n",
    "                    test_logers=train_info.test_losses)\n",
    "\n",
    "        previous_time = current_time\n",
    "        current_time = datetime.now()\n",
    "        epoch_took = current_time - previous_time\n",
    "\n",
    "        sec_took = (current_time - train_info.start_t).seconds\n",
    "        speed = sec_took / train_info.epoch\n",
    "\n",
    "        print_str = f\"| Epoch [{train_info.epoch}] Done | It has took [{sec_took/60:.2f}] min, Avg time: [{speed:.2f}] sec/epoch | Estimate time for [{num_epochs}] epochs: [{speed*num_epochs/60:.2f}] min | Epoch took [{epoch_took.seconds}] sec | \"\n",
    "\n",
    "        if lr_scheduler and hasattr(lr_scheduler, \"num_bad_epochs\"):\n",
    "            print_str += f\"Patience [{lr_scheduler.num_bad_epochs}] |\"\n",
    "\n",
    "        print_f.print_title(print_str)\n",
    "\n",
    "        #######################################################################################\n",
    "        if setup.save_early_stop_model:\n",
    "            val_ar, val_ap, train_info = check_best(\n",
    "                setup=setup,\n",
    "                val_ap_ar=val_ap_ar,\n",
    "                device=device,\n",
    "                eval_params_dict=eval_params_dict,\n",
    "                train_info=train_info,\n",
    "                model=model,\n",
    "                optim=optimizer,\n",
    "                test_dataloader=test_dataloader,\n",
    "                test_coco=test_coco,\n",
    "                iou_types=iou_types,\n",
    "                score_thres=None,\n",
    "                dynamic_weight=dynamic_loss_weight,\n",
    "            )\n",
    "\n",
    "    val_ap_ar = get_ap_ar(train_info.last_val_evaluator)\n",
    "\n",
    "    train_info = end_train(\n",
    "        setup=setup,\n",
    "        train_info=train_info,\n",
    "        model=model,\n",
    "        optim=optimizer,\n",
    "        eval_params_dict=eval_params_dict,\n",
    "        last_val_ar=val_ap_ar[\"ar\"],\n",
    "        last_val_ap=val_ap_ar[\"ap\"],\n",
    "        test_dataloader=test_dataloader,\n",
    "        device=device,\n",
    "        test_coco=test_coco,\n",
    "        iou_types=iou_types,\n",
    "        score_thres=None,\n",
    "        dynamic_weight=dynamic_loss_weight,\n",
    "    )\n",
    "\n",
    "    train_infos.append(train_info)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "05ebdd47fe7a4051acc4227c2d648dd2aae7424f451cfb0e2d4bf70d17920b33"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
